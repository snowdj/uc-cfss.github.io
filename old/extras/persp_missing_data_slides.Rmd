---
title: "Missing data and multiple imputation"
author: |
  | MACS 30200
  | University of Chicago
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

library(tidyverse)
library(forcats)
library(broom)
library(modelr)
library(stringr)
library(titanic)
library(rcfss)
library(car)
library(plotly)
library(haven)
library(coefplot)

options(digits = 3)
set.seed(1234)
theme_set(theme_minimal(base_size = 22))
```

## Causes of missingness

* Surveys
* Errors in data collection
* Intentional
* Censored values

## Patterns of missingness

* Missing completely at random (MCAR)
* Missing at random (MAR)
* Missing not at random (MNAR)
* Why do we care?
    * Mechanism
    * Ignorable vs. non-ignorable

----

```{r sim-data}
n_sim <- 250 # Number of random samples

# Target parameters for univariate normal distributions
rho <- 2 / 3

mu1 <- 10
mu2 <- 20

s1 <- 9
s2 <- 16
s1s2 <- sqrt(s1) * sqrt(s2) * rho

# Parameters for bivariate normal distribution
mu <- c(mu1, mu2) # Mean 
sigma <- matrix(c(s1, s1s2, s1s2, s2), 2) # Covariance matrix
data_sim <- MASS::mvrnorm(n_sim, mu, sigma) %>%
  as_tibble %>%
  rename(x1 = V1,
         x2 = V2)
```

```{r sim-mod}
# correlation coefficient
# cor(data_sim)

# regression models
# lm(x2 ~ x1, data = data_sim)
# lm(x1 ~ x2, data = data_sim)

# plot of data
ggplot(data_sim, aes(x1, x2)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Complete data",
       x = expression(X[1]),
       y = expression(X[2]))
```

----

```{r sim-mcar}
mcar <- data_sim %>%
  mutate(na = ifelse(row_number(x2) %in% sample(seq_len(n_sim), 100), TRUE, FALSE))

ggplot(mcar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mcar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing completely at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing") +
  theme(legend.position = "bottom",
        legend.box = "vertical")
```

----

```{r sim-mar}
mar <- data_sim %>%
  mutate(na = .5 + (2 / 3) * (x1 - 10) + rnorm(n_sim, sd = 2),
         na = logit2prob(na),
         na = as.logical(round(na)))

ggplot(mar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing") +
  theme(legend.position = "bottom",
        legend.box = "vertical")
```

----

```{r sim-mnar}
mnar <- data_sim %>%
  mutate(na = .5 + (1 / 2) * (x2 - 20) + rnorm(n_sim, sd = 2),
         na = logit2prob(na),
         na = as.logical(round(na)))

ggplot(mnar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mnar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing not at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing") +
  theme(legend.position = "bottom",
        legend.box = "vertical")
```

## Things to consider

1. Does the method provide **consistent estimates** of the population parameters?
1. Does the method provide **valid statistical inferences**?
1. Does the method use the observed data **efficiently** or does it recklessly discard information?

## Complete-case analysis

* Listwise deletion
* Advantages
* Disadvantages

## Available-case analysis

* Pairwise deletion
* Advantages
* Disadvantages

## Imputation

* Imputation
* Unconditional mean imputation
* Conditional mean imputation

----

```{r compare-imputation, fig.show = "hide"}
get_miss_stat <- function(df){
  df %>%
    summarize(mu_1 = mean(x1, na.rm = TRUE),
              mu_2 = mean(x2, na.rm = TRUE),
              sigma_1 = var(x1, use = "complete.obs"),
              sigma_2 = var(x2, use = "complete.obs"),
              sigma_12 = cov(., use = "complete.obs")[1, 2],
              rho = cor(., use = "complete.obs")[1, 2],
              beta_12 = lm(x2 ~ x1, data = .) %>% coef(.) %>% .[[2]],
              beta_21 = lm(x1 ~ x2, data = .) %>% coef(.)%>% .[[2]]
    )
}

data_miss <- list(
  mcar = data_sim %>%
    mutate(x2 = replace(x2, sample(seq_len(n_sim), 100), NA)),
  mar = data_sim %>%
    mutate(na = .5 + (2 / 3) * (x1 - 10) + rnorm(n_sim, sd = 2),
           na = logit2prob(na),
           na = as.logical(round(na)),
           x2 = replace(x2, na, NA)) %>%
    select(-na),
  mnar = data_sim %>%
    mutate(na = .5 + (1 / 2) * (x2 - 20) + rnorm(n_sim, sd = 2),
           na = logit2prob(na),
           na = as.logical(round(na)),
           x2 = replace(x2, na, NA)) %>%
    select(-na)
)

# complete cases
complete_cases <- data_miss %>%
  map(na.omit) %>%
  map_df(get_miss_stat, .id = "id")

# available cases
available_cases <- data_miss %>%
  map_df(~ .x %>%
    summarize(mu_1 = mean(x1, na.rm = TRUE),
              mu_2 = mean(x2, na.rm = TRUE),
              sigma_1 = var(x1, use = "complete.obs"),
              sigma_2 = var(x2, use = "complete.obs"),
              sigma_12 = cov(., use = "pairwise.complete.obs")[1, 2],
              rho = cor(., use = "pairwise.complete.obs")[1, 2],
              beta_12 = psych::mat.regress("x2", "x1",
                   data = cov(., use = "pairwise.complete.obs"),
                   n.obs = nrow(na.omit(.))) %>%
                .$beta %>%
                .[[1]],
              beta_21 = psych::mat.regress("x1", "x2",
                   data = cov(., use = "pairwise.complete.obs"),
                   n.obs = nrow(na.omit(.))) %>%
                .$beta %>%
                .[[1]]
    ), .id = "id")

# mean imputation
mean_imp <- data_miss %>%
  map(~ mutate(.x, x2 = ifelse(is.na(x2), mean(x2, na.rm = TRUE), x2))) %>%
  map_df(get_miss_stat, .id = "id")

# regression imputation
reg_imp <- data_miss %>%
  map(~ .x %>%
        mutate(x2_imp = lm(x2 ~ x1, data = .) %>%
                 predict(., newdata = .x),
               x2 = ifelse(is.na(x2), x2_imp, x2))) %>%
  map_df(get_miss_stat, .id = "id")

sum_stats <- bind_rows(
  `Population parameters` = data_frame(
    mu_1 = 10,
    mu_2 = 20,
    sigma_1 = 9,
    sigma_2 = 16,
    sigma_12 = 8,
    rho = .667,
    beta_12 = .5,
    beta_21 = .889),
  `Complete data` = get_miss_stat(data_sim),
  `Complete cases` = complete_cases,
  `Available cases` = available_cases,
  `Mean imputation` = mean_imp,
  `Regression imputation` = reg_imp,
  .id = "method"
) %>%
  mutate(id = ifelse(method == "Population parameters", "Parameter", id),
         id = ifelse(method == "Complete data", "Complete data", id)) %>%
  gather(param, value, -method, -id) %>%
  mutate(param = ifelse(param == "mu_1", "mu[1]", param),
         param = ifelse(param == "mu_2", "mu[2]", param),
         param = ifelse(param == "sigma_1", "sigma[1]^2", param),
         param = ifelse(param == "sigma_2", "sigma[2]^2", param),
         param = ifelse(param == "sigma_12", "sigma[12]", param),
         param = ifelse(param == "beta_12", "beta[12]", param),
         param = ifelse(param == "beta_21", "beta[21]", param))
```

```{r compare-imputation-plot}
sum_stats %>%
  filter(id %in% c("mcar", "mar", "mnar")) %>%
  mutate(id = factor(id, levels = c("mcar", "mar", "mnar"),
                     labels = c("MCAR", "MAR", "MNAR"))) %>%
  ggplot(aes(forcats::fct_rev(id), value, color = method, shape = method)) +
  coord_flip() +
  facet_wrap( ~ param, nrow = 2, scales = "free_x",
              labeller = "label_parsed") +
  geom_point() +
  geom_hline(data = filter(sum_stats, id == "Parameter"),
             aes(yintercept = value)) +
  scale_color_brewer(type = "qual", palette = "Dark2", 
                     guide = guide_legend(nrow = 2)) +
  labs(x = NULL,
       y = "Estimated parameter value",
       color = NULL,
       shape = NULL) +
  theme(legend.position = "bottom",
        axis.text.x = element_text(size = 12))
```

## Maximum-likelihood estimation

$$p(\mathbf{X}, \theta) = p(\mathbf{X}_{\text{obs}}, \mathbf{X}_{\text{mis}}; \theta)$$

* Data MAR

    $$p(\mathbf{X}_\text{obs}; \theta) = \int{p(\mathbf{X}_{\text{obs}}, \mathbf{X}_{\text{mis}}; \theta)} d\mathbf{X}_{\text{mis}}$$

* EM algorithm
* Single model for all variables

## Predictive mean matching

1. For cases with no missing data, estimate a linear regression of $x$ on $z$, producing a set of coefficients $b$
1. Make a random draw from the **posterior predictive distribution** of $b$, producing a new set of coefficients $b*$
1. Using $b*$, generate predicted values for $x$ for all cases
1. For each case with missing $x$, identify a set of cases with observed $x$ whose predicted values are close to the predicted value for the case with missing data
1. From among those close cases, randomly choose one and assign its observed value to substitute for the missing value

## Non-parametric models

* Random forests
* Deep learning

## Multiple imputation

* Generate multiple imputed datasets
* Bayesian multiple imputation
* Account for uncertainty within and across the datasets

## Conducting inference

$$\tilde{\beta}_j \equiv \frac{\sum_{l=1}^g B_j^{(l)}}{g}$$

## Conducting inference

$$\tilde{\text{SE}}(\tilde{\beta}_j) = \sqrt{V_j^{(W)} + \frac{g + 1}{g} V_j^{(B)}}$$

$$V_j^{(W)} = \frac{\sum_{l=1}^g \text{SE}^2(B_j^{(l)})}{g}$$

$$V_j^{(B)} = \frac{\sum_{l=1}^g (B_j^{(l)} - \tilde{B}_j)^2}{g-1}$$

$$\text{SE}^2(B_j^{(l)})$$

## Practical considerations for multiple imputation

* Which variables to include
* Transform variables to approximately normal
* Adjust the imputed data to resemble the original data
* Make sure the imputation model captures relevant features of the data
* $g$ doesn't need to be large

## Infant mortality

```{r import-un}
un <- read_delim("../data/UnitedNations.txt", delim = " ")
```

```{r plot-infant-gdp}
ggplot(un, aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  scale_x_continuous(labels = scales::dollar) +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")
```

## Regression model {.scrollable}

```{r log-log}
ggplot(un, aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_log10(labels = scales::dollar) +
  scale_y_log10() +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")

mortal_mod <- lm(log(infantMortality) ~ log(GDPperCapita) +
                   contraception + educationFemale,
                 data = un)
tidy(mortal_mod)
```

## Missingness

```{r miss-pattern}
un %>%
  select(infantMortality, GDPperCapita, contraception, educationFemale) %>%
  summarize_all(funs(sum(is.na(.)))) %>%
  knitr::kable()
```

## Amelia {.scrollable}

```{r un-amelia, echo = TRUE}
library(Amelia)
un.out <- amelia(as.data.frame(un), m = 5,
                 idvars = c("country", "region"))
```

```{r amelia-result}
str(un.out$imputations, max.level = 2)
```

## MI scatterplot

```{r plot-imput}
un.out$imputations %>%
  map(as.data.frame) %>%
  bind_rows(.id = "impute") %>%
  ggplot(aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  scale_x_continuous(labels = scales::dollar) +
  facet_grid(impute ~ .) +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")
```

## Conducting inference

```{r amelia-purrr}
models_imp <- data_frame(data = un.out$imputations) %>%
  mutate(model = map(data, ~ lm(log(infantMortality) ~ log(GDPperCapita) +
                                  contraception + educationFemale,
                                data = .x)),
         coef = map(model, tidy)) %>%
  unnest(coef, .id = "id")
models_imp
```

## Conducting inference

```{r mi-meld}
mi.meld.plus <- function(df_tidy){
  # transform data into appropriate matrix shape
  coef.out <- df_tidy %>%
    select(id:estimate) %>%
    spread(term, estimate) %>%
    select(-id)
  
  se.out <- df_tidy %>%
    select(id, term, std.error) %>%
    spread(term, std.error) %>%
    select(-id)
  
  combined.results <- mi.meld(q = coef.out, se = se.out)
  
  data_frame(term = colnames(combined.results$q.mi),
             estimate.mi = combined.results$q.mi[1, ],
             std.error.mi = combined.results$se.mi[1, ])
}

# compare results
tidy(mortal_mod) %>%
  left_join(mi.meld.plus(models_imp)) %>%
  select(-statistic, -p.value)
```

## Missingness map

```{r miss-map}
missmap(un.out)
```

## Transforming variables

```{r heatmap}
GGally::ggpairs(select_if(un, is.numeric))
```

## Transforming variables

```{r select-un}
un_lite <- un %>%
  select(infantMortality, GDPperCapita, contraception, educationFemale,
         tfr, lifeFemale, economicActivityFemale, illiteracyFemale)

GGally::ggpairs(un_lite)
```

## Transforming variables

```{r amelia-transform, echo = TRUE}
un_lite.out <- amelia(un_lite, m = 5,
                      logs = c("infantMortality", "GDPperCapita"),
                      sqrt = c("tfr"))
```

## New model results {.scrollable}

```{r amelia-trans-mod}
models_trans_imp <- data_frame(data = un_lite.out$imputations) %>%
  mutate(model = map(data, ~ lm(log(infantMortality) ~ log(GDPperCapita) +
                                  contraception + educationFemale,
                                data = .x)),
         coef = map(model, tidy)) %>%
  unnest(coef, .id = "id")
models_trans_imp

# compare results
tidy(mortal_mod) %>%
  left_join(mi.meld.plus(models_trans_imp)) %>%
  select(-statistic, -p.value)

# cheating on my confidence intervals for this plot
bind_rows(orig = tidy(mortal_mod),
          full_imp = mi.meld.plus(models_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          trans_imp = mi.meld.plus(models_trans_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          .id = "method") %>%
  mutate(method = factor(method, levels = c("orig", "full_imp", "trans_imp"),
                         labels = c("Listwise deletion", "Full imputation",
                                    "Transformed imputation")),
         term = factor(term, levels = c("(Intercept)", "contraception",
                                        "educationFemale", "log(GDPperCapita)"),
                       labels = c("Intercept", "Contraception", "Female education",
                                  "GDP per capita (log)"))) %>%
  ggplot(aes(fct_rev(term), estimate, color = fct_rev(method),
             ymin = estimate - 1.96 * std.error,
             ymax = estimate + 1.96 * std.error)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_pointrange(position = position_dodge(.75)) +
  coord_flip() +
  scale_color_discrete(guide = guide_legend(reverse = TRUE)) +
  labs(title = "Comparing regression results",
       x = NULL,
       y = "Estimated parameter",
       color = NULL) +
  theme(legend.position = "bottom")

bind_rows(orig = tidy(mortal_mod),
          full_imp = mi.meld.plus(models_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          trans_imp = mi.meld.plus(models_trans_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          .id = "method") %>%
  mutate(method = factor(method, levels = c("orig", "full_imp", "trans_imp"),
                         labels = c("Listwise deletion", "Full imputation",
                                    "Transformed imputation")),
         term = factor(term, levels = c("(Intercept)", "contraception",
                                        "educationFemale", "log(GDPperCapita)"),
                       labels = c("Intercept", "Contraception", "Female education",
                                  "GDP per capita (log)"))) %>%
  filter(term != "Intercept") %>%
  ggplot(aes(fct_rev(term), estimate, color = fct_rev(method),
             ymin = estimate - 1.96 * std.error,
             ymax = estimate + 1.96 * std.error)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_pointrange(position = position_dodge(.75)) +
  coord_flip() +
  scale_color_discrete(guide = guide_legend(reverse = TRUE)) +
  labs(title = "Comparing regression results",
       subtitle = "Omitting intercept from plot",
       x = NULL,
       y = "Estimated parameter",
       color = NULL) +
  theme(legend.position = "bottom")
```


