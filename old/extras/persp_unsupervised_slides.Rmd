---
title: "Statistical learning: unsupervised learning"
author: |
  | MACS 30100
  | University of Chicago
date: "March 8, 2017"
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

library(tidyverse)
library(forcats)
library(broom)
library(modelr)
library(stringr)
library(ISLR)
library(titanic)
library(rcfss)
library(grid)
library(gridExtra)
library(ggdendro)
library(tidytext)
library(tm)
library(topicmodels)

options(digits = 3)
set.seed(1234)
theme_set(theme_minimal(base_size = 22))
```

## Unsupervised learning

* Supervised learning
* Unsupervised learning
    * Exploration

## Clustering methods

* Clustering
* $K$-means clustering
* Hierarchical clustering

## $K$-means clustering

```{r kmeans}
# generate data
x <- data_frame(x1 = rnorm(150) + 3,
                x2 = rnorm(150) - 4)

# estimate k clusters
x.out <- x %>%
  mutate(k2 = kmeans(x, 2, nstart = 20)$cluster,
         k3 = kmeans(x, 3, nstart = 20)$cluster,
         k4 = kmeans(x, 4, nstart = 20)$cluster)

# plot clusters
x.out %>%
  gather(K, pred, k2:k4) %>%
  mutate(K = parse_numeric(K),
         pred = factor(pred)) %>%
  ggplot(aes(x1, x2, color = pred)) +
  facet_grid(. ~ K, labeller = label_both) +
  geom_point() +
  theme(legend.position = "none")
```

## $K$-means clustering

* $C_1, C_2, \dots, C_K$: indicies of observations in each cluster
* Minimize the within-cluster variation

    $$\min_{C_1, C_2, \dots, C_K} \left\{ \sum_{k = 1}^K W(C_k) \right\}$$

* Squared Euclidean distance

    $$W(C_k) = \frac{1}{|C_k|} \sum_{i,i' \in C_k} \sum_{j = 1}^p (x_{ij} - x_{i'j})^2$$

* Global vs. local optimum

## $K$-means clustering

1. Randomly assign each observation to one of $K$ clusters
1. For each of the $K$ clusters:
    1. Compute the cluster centroid
    1. Reassign observations
1. Rinse and repeat until stable

## $K$-means clustering

```{r kmeans-sim-start}
kmean.out <- rerun(6, kmeans(x, 3, nstart = 1))

kmean.out %>%
  map_df(~ as_tibble(.$cluster), .id = "id") %>%
  bind_cols(bind_rows(x,x,x,x,x,x)) %>%
  mutate(withinss = rep(map_chr(kmean.out, ~ .$tot.withinss), each = nrow(x)),
         value = factor(value)) %>%
  ggplot(aes(x1, x2, color = value)) +
  facet_wrap(~ id + withinss, ncol = 3, labeller = label_wrap_gen(multi_line = FALSE)) +
  geom_point() +
  theme(legend.position = "none")
```

## Hierarchical clustering

* Fixed $K$
* Hierarchical clustering
* Dendrograms

## Interpreting dendrograms

```{r dendro-sim}
# generate data
x <- data_frame(x1 = rnorm(50) + 3,
                x2 = rnorm(50) - 4,
                y = ifelse(x1 < 3, "1",
                           ifelse(x2 > -4, "2", "3")))

ggplot(x, aes(x1, x2, color = y)) +
  geom_point() +
  labs(title = "Simulated data",
       x = expression(X[1]),
       y = expression(X[2])) +
  theme(legend.position = "none")
```

## Interpreting dendrograms

```{r dendro-cluster, dependson="dendro-sim"}
# estimate hierarchical cluster
hc.complete <- hclust(dist(x), method = "complete")

# plot
ggdendrogram(hc.complete)
```

## Interpreting dendrograms

```{r dendro-cut-4}
h <- 4
# extract dendro data
hcdata <- dendro_data(hc.complete)
hclabs <- label(hcdata) %>%
  left_join(data_frame(label = as.factor(seq.int(nrow(x))),
                       cl = as.factor(cutree(hc.complete, h = h))))

# plot dendrogram
ggdendrogram(hc.complete, labels = FALSE) +
  geom_text(data = hclabs,
            aes(label = label, x = x, y = 0, color = cl),
            vjust = .5, angle = 90) +
  geom_hline(yintercept = h, linetype = 2) +
  theme(axis.text.x = element_blank(),
        legend.position = "none")
```

## Interpreting dendrograms

```{r dendro-cut-3}
h <- 3
# extract dendro data
hcdata <- dendro_data(hc.complete)
hclabs <- label(hcdata) %>%
  left_join(data_frame(label = as.factor(seq.int(nrow(x))),
                       cl = as.factor(cutree(hc.complete, h = h))))

# plot dendrogram
ggdendrogram(hc.complete, labels = FALSE) +
  geom_text(data = hclabs,
            aes(label = label, x = x, y = 0, color = cl),
            vjust = .5, angle = 90) +
  geom_hline(yintercept = h, linetype = 2) +
  theme(axis.text.x = element_blank(),
        legend.position = "none")
```

## Estimating hierarchical clusters

1. Assume each $n$ observation is its own cluster and calculate pairwise dissimilarities
1. For $i=n, n-1, \dots, 2$:
    1. Identify least dissimilar pair of clusters and fuse them
    1. Compute the new pairwise inter-cluster dissimilarities among the $i-1$ clusters
1. Rinse and repeat until only a single cluster remains

## Linkage

* Complete
* Single
* Average
* Centroid

## Linkage

```{r dendro-complete}
hc.complete <- hclust(dist(x), method = "complete")
hc.single <- hclust(dist(x), method = "single")
hc.average <- hclust(dist(x), method = "average")

# plot
ggdendrogram(hc.complete) +
  labs(title = "Complete linkage")
```

## Linkage

```{r dendro-single}
ggdendrogram(hc.single) +
  labs(title = "Single linkage")
```

## Linkage

```{r dendro-average}
ggdendrogram(hc.average) +
  labs(title = "Average linkage")
```

## Dimension reduction

* Visualize data with lots of variables
* Use variables in supervised learning, but you have too many
* Identify a small number of variables that collectively explain most of the variablity in the original data

## DW-NOMINATE

* Studying legislative voting
* Roll-call votes
* Multidimensional scaling techniques
* DW-NOMINATE dimensions
    * Ideology (liberal-conservative)
    * Issue of the day

----

![[Voteview.org](http://voteview.org/political_polarization_2015.htm)](http://voteview.org/images/png/house_party_means_1879-2015.png)

----

![[Voteview.org](http://voteview.org/political_polarization_2015.htm)](http://voteview.org/images/png/house_party_means_1879-2015_2nd.png)

----

![[Voteview.org](http://voteview.org/political_polarization_2015.htm)](http://voteview.org/images/png/senate_party_means_1879-2015.png)

----

![[Voteview.org](http://voteview.org/political_polarization_2015.htm)](http://voteview.org/images/png/senate_party_means_1879-2015_2nd.png)

## Principal components analysis

* Find a low-dimensional representation of the data that contains as much as possible of the variation
* Dimensions are linear combinations of the variables

## First principal component

$$Z_1 = \phi_{11}X_1 + \phi_{21}X_2 + \dots + \phi_{p1}X_p$$

$$\sum_{j=1}^p \phi_{j1}^2 = 1$$

## Estimation procedure

$$\max_{\phi_{11}, \dots, \phi_{p1}} \left \{ \frac{1}{n} \sum_{i=1}^n z_{i1}^2 \right \}$$

Such that $\sum_{j=1}^p \phi_{j1}^2 = 1$

## Result of estimation

* Loadings: $\phi_{11}, \dots, \phi_{p1}$
* Scores: $z_{11}, z_{21}, \dots, z_{n1}$
* Estimating second PC, third PC, etc.

## Biplot of `USArrests`

```{r pca-usarrests}
pr.out <- prcomp(USArrests, scale = TRUE)

biplot(pr.out, scale = 0, cex = .8)
```

## Bag-of-words

```
 a abandoned abc ability able about above abroad absorbed absorbing abstract
43         0   0       0    0    10     0      0        0         0        1
```

1. Sparsity
1. Stop words
1. Correlation between words

## Latent semantic analysis

* Identify words closely related to one another
* Makes searching by keyword easier
* Uses PCA or similar techinques

## `NYTimes`

```{r nytimes}
# get NYTimes data
load("../data/pca-examples.Rdata")
```

```{r nytimes-words}
colnames(nyt.frame)[sample(ncol(nyt.frame),30)]
```

## `NYTimes`

```{r nytimes-pca}
# Omit the first column of class labels
nyt.pca <- prcomp(nyt.frame[,-1])

# Extract the actual component directions/weights for ease of reference
nyt.latent.sem <- nyt.pca$rotation

# convert to data frame
nyt.latent.sem <- nyt.latent.sem %>%
  as_tibble %>%
  mutate(word = names(nyt.latent.sem[,1])) %>%
  select(word, everything())
```

```{r nytimes-PC1}
nyt.latent.sem %>%
  select(word, PC1) %>%
  arrange(PC1) %>%
  slice(c(1:10, (n() - 10):n())) %>%
  mutate(pos = ifelse(PC1 > 0, TRUE, FALSE),
         word = fct_reorder(word, PC1)) %>%
  ggplot(aes(word, PC1, fill = pos)) +
  geom_col() +
  labs(title = "LSA analysis of NYTimes articles",
       x = NULL,
       y = "PC1 scores") +
  coord_flip() +
  theme(legend.position = "none")
```

## `NYTimes`

```{r nytimes-PC2}
nyt.latent.sem %>%
  select(word, PC2) %>%
  arrange(PC2) %>%
  slice(c(1:10, (n() - 10):n())) %>%
  mutate(pos = ifelse(PC2 > 0, TRUE, FALSE),
         word = fct_reorder(word, PC2)) %>%
  ggplot(aes(word, PC2, fill = pos)) +
  geom_col() +
  labs(title = "LSA analysis of NYTimes articles",
       x = NULL,
       y = "PC2 scores") +
  coord_flip() +
  theme(legend.position = "none")
```

## `NYTimes`

```{r nytimes-biplot}
biplot(nyt.pca, scale = 0, cex = .6)
```

## `NYTimes`

```{r nytimes-plot-dim}
cbind(type = nyt.frame$class.labels, as_tibble(nyt.pca$x[,1:2])) %>%
  mutate(type = factor(type, levels = c("art", "music"),
                       labels = c("A", "M"))) %>%
  ggplot(aes(PC1, PC2, label = type, color = type)) +
  geom_text() +
  labs(title = "")
  theme(legend.position = "none")
```

## Topic modeling

* Themes
* Probabilistic topic models
* Latent Dirichlet allocation

## Food and animals

1. I ate a banana and spinach smoothie for breakfast.
1. I like to eat broccoli and bananas.
1. Chinchillas and kittens are cute.
1. My sister adopted a kitten yesterday.
1. Look at this cute hamster munching on a piece of broccoli.

## LDA document structure

* Decide on the number of words N the document will have
    * [Dirichlet probability distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)
    * Fixed set of $k$ topics
* Generate each word in the document:
    * Pick a topic
    * Generate the word
* LDA backtracks from this assumption

## Food and animals

* Decide that $D$ will be 1/2 about food and 1/2 about cute animals.
* Pick 5 to be the number of words in $D$.
* Pick the first word to come from the food topic
* Pick the second word to come from the cute animals topic
* Pick the third word to come from the cute animals topic
* Pick the fourth word to come from the food topic
* Pick the fifth word to come from the food topic

## How does LDA learn?

* Randomly assign each word in the document to one of $K$ topics
* For each document $d$:
    * Go through each word $w$ in $d$
        * And for each topic $t$, compute two things:
            1. $p(t | d)$
            1. $p(w | t)$
        * Reassign $w$ a new topic $t$ with probability $p(t|d) \times p(w|t)$
* Rinse and repeat

* Estimate from LDA
    1. The topic mixtures of each document
    1. The words associated to each topic


## Associated Press articles

```{r associated_press}
data("AssociatedPress", package = "topicmodels")

# tidy and remove stop words
ap_td <- tidy(AssociatedPress)
```

```{r ap_stopwords, dependson = "associated_press"}
ap_dtm <- ap_td %>%
  anti_join(stop_words, by = c(term = "word")) %>%
  cast_dtm(document, term, count)
ap_dtm
```

----

```{r ap_topic_4, dependson = "associated_press"}
ap_lda <- LDA(ap_dtm, k = 4, control = list(seed = 1234))
```

```{r ap_4_topn, include = TRUE}
ap_lda_td <- tidy(ap_lda)

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 2) +
  coord_flip()
```

----

```{r ap_topic_12, dependson = "associated_press"}
ap_lda <- LDA(ap_dtm, k = 12, control = list(seed = 1234))
```

```{r ap_12_topn, dependson="ap_topic_12", include = TRUE, fig.height = 8}
ap_lda_td <- tidy(ap_lda)

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 3) +
  coord_flip()
```

## Perplexity

* A statistical measure of how well a probability model predicts a sample
* Given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents
* Perplexity for LDA model with 12 topics
    * `r topicmodels::perplexity(ap_lda)`

----

```{r ap_lda_compare, dependson="associated_press"}
n_topics <- c(2, 4, 10, 20, 50, 100)

if(file.exists("../extras/ap_lda_compare.Rdata")){
  load(file = "../extras/ap_lda_compare.Rdata")
} else{
  ap_lda_compare <- n_topics %>%
    map(LDA, x = ap_dtm, control = list(seed = 1234))
}
```

```{r ap_lda_compare_viz, dependson="ap_lda_compare", include = TRUE} 
data_frame(k = n_topics,
           perplex = map_dbl(ap_lda_compare, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line() +
  labs(title = "Evaluating LDA topic models",
       subtitle = "Optimal number of topics (smaller is better)",
       x = "Number of topics",
       y = "Perplexity")
```

## Topics from $k=100$

```{r ap_100_topn, dependson="ap_lda_compare", include = TRUE}
ap_lda_td <- tidy(ap_lda_compare[[6]])

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  filter(topic <= 12) %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 3) +
  coord_flip()
```



