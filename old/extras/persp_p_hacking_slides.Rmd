---
title: "p-hacking"
author: |
  | MACS 30200
  | University of Chicago
date: "May 17, 2017"
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

library(tidyverse)
library(broom)
library(forcats)
library(modelr)
library(stringr)
library(car)
library(rcfss)
library(coefplot)
library(RColorBrewer)
library(lme4)

options(digits = 3)
set.seed(1234)
theme_set(theme_minimal(base_size = 22))
```

## Hypothesis testing

* Sample vs. population
* Hypothesis testing
    * Null hypothesis
    * Alternative hypothesis
    * $H_0$: $\beta_1 = 0$
    * $H_a$: $\beta_1 \neq 0$
* Regression coefficients

    $$t = \frac{\hat{\beta}_1 - 0}{\text{SE}(\hat{\beta}_1)}$$

* p-value

## $p < .05$

![](http://marginalrevolution.com/wp-content/uploads/2014/05/Type-I-and-II-errors1-625x468.jpg)

## What p-values can and cannot do

> A p-value is the probability under a specified statistical model that a statistical summary of the data would be equal to or more extreme than its observed values.

* Frequentist inference
* Indicate how incompatible the data are with a specified statistical model
* Does not prove the alternative hypothesis to be true
* Does not prove the null hypothesis to be true

## What p-values can and cannot do

![](http://www.azquotes.com/picture-quotes/quote-the-absence-of-evidence-is-not-the-evidence-of-absence-carl-sagan-43-51-12.jpg)
    
## What p-values can and cannot do

* $0.05$ threshold
* Size and importance of a result
* Other plausible explanations

## How to find a significant p-value

```{r pval-sim}
n_obs <- 100

pval_dist <- function(n_obs){
  x <- replicate(10, rnorm(n_obs))
  y <- rnorm(n_obs)
  
  mod <- lm(y ~ x[, sample(1:10, 1)])
  
  return(tidy(mod)[2,])
}

pvals <- 1000 %>%
  rerun(pval_dist(n_obs)) %>%
  bind_rows %>%
  as_tibble %>%
  mutate(sig = p.value < .05)

ggplot(pvals, aes(p.value, fill = sig)) +
  geom_histogram(binwidth = .025, boundary = 0) +
  labs(title = "Distribution of p-values when null is true",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## How to find a significant p-value

```{r pval-sim-mult-test}
pval_dist_mult <- function(n_obs){
  # generate simulated data
  x <- replicate(10, rnorm(n_obs))
  y <- rnorm(n_obs)
  
  # estimate a linear model for each column in x and find min pvalue
  x %>%
    as_tibble %>%
    mutate(y = y) %>%
    gather(i, x, -y) %>%
    group_by(i) %>%
    nest() %>%
    mutate(mod = map(data, ~ lm(y ~ x, data = .x)),
           results = map(mod, tidy)) %>%
    unnest(results) %>%
    filter(term == "x") %>%
    filter(p.value == min(p.value))
}

pvals_mult <- 1000 %>%
  rerun(pval_dist_mult(n_obs)) %>%
  bind_rows %>%
  as_tibble %>%
  mutate(sig = p.value < .05)

ggplot(pvals_mult, aes(p.value, fill = sig)) +
  geom_histogram(binwidth = .025, boundary = 0) +
  labs(title = "Distribution of minimmum p-values for\n10 tests when null is true",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## How to find a significant p-value

* False discovery
* Selection bias
* Researcher degrees of freedom

## Confidence intervals don't save us

```{r ci-single-test}
ggplot(pvals, aes(p.value, estimate, color = sig)) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(ymin = estimate - 1.96 * std.error,
                      ymax = estimate + 1.96 * std.error), alpha = .25) +
  labs(title = "95% CIs when null is true",
       x = expression(P),
       y = "Estimated effect size") +
  theme(legend.position = "none")
```

## Confidence intervals don't save us

```{r ci-mult-test}
ggplot(pvals_mult, aes(p.value, estimate, color = sig)) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(ymin = estimate - 1.96 * std.error,
                      ymax = estimate + 1.96 * std.error), alpha = .25) +
  labs(title = "Most significant 95% CIs of 10 tests\nwhen null is true",
       x = expression(P),
       y = "Estimated effect size") +
  theme(legend.position = "none")
```

## Best subset selection

1. Let $M_0$ denote the null model which contains no predictors. This model simply predicts the sample mean for each observation.
1. For $k = 1, 2, \dots, p$:
    1. Fit all ${p}\choose{k}$ models that contain exactly $k$ predictors
    1. Pick the best among these ${p}\choose{k}$ models and call it $M_k$. Best is defined by the smallest RSS or RMSE, or largest $R^2$
1. Select a single best model from among $M_0, \dots, M_p$ using cross-validated prediction error or similar metrics

## Forward stepwise regression

1. Let $M_0$ denote the null model which contains no predictors
1. For $k = 1, 2, \dots, p - 1$:
    1. Fit all $p-k$ models that augment the predictors in $M_k$ with one additional predictor
    1. Pick the best among these $p - k$ models and call it $M_{k+1}$. Best is defined by the smallest RSS or RMSE, or largest $R^2$
1. Select a single best model from among $M_0, \dots, M_p$ using cross-validated prediction error or similar metrics

## Backward stepwise regression

1. Let $M_0$ denote the full model which contains all $p$ predictors
1. For $k = p, p-1, \dots, 1$:
    1. Fit all $k$ models that contain all but one of the predictors in $M_k$, for a total of $k-1$ predictors
    1. Pick the best among these $k$ models and call it $M_{k-1}$. Best is defined by the smallest RSS or RMSE, or largest $R^2$
1. Select a single best model from among $M_0, \dots, M_p$ using cross-validated prediction error or similar metrics

## Subset selection and p-values

```{r sim-step-single}
full_mod_sim <- function(n_obs){
  x <- replicate(10, rnorm(n_obs))
  y <- rnorm(n_obs)
  
  mod <- lm(y ~ x)
  
  return(tidy(mod))
}

pvals_full <- 1000 %>%
  rerun(full_mod_sim(n_obs)) %>%
  bind_rows %>%
  as_tibble %>%
  filter(term != "(Intercept)") %>%
  mutate(sig = p.value < .05)

ggplot(pvals_full, aes(p.value, fill = sig)) +
  geom_histogram(binwidth = .025, boundary = 0) +
  labs(title = "Distribution of p-values from full model\nwhen null is true",
       subtitle = "All covariates",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## Subset selection and p-values {.scrollable}

```{r sim-step-mult, eval = FALSE}
step_mod_sim <- function(n_obs){
  x <- replicate(10, rnorm(n_obs)) %>%
    as_tibble()
  y <- rnorm(n_obs)
  
  sim_data <- x %>%
    mutate(y = y)
  
  # estimate full model
  mod <- lm(y ~ ., data = sim_data)
  
  # pick model with lowest aic based on forward stepwise selection
  invisible(MASS::stepAIC(mod))
}

pvals_step <- 1000 %>%
  rerun(step_mod_sim(n_obs))
```

```{r sim-step-mult-real, include = FALSE}
step_mod_sim <- function(n_obs){
  x <- replicate(10, rnorm(n_obs)) %>%
    as_tibble()
  y <- rnorm(n_obs)
  
  sim_data <- x %>%
    mutate(y = y)
  
  # estimate full model
  mod <- lm(y ~ ., data = sim_data)
  
  # pick model with lowest aic based on forward stepwise selection
  invisible(MASS::stepAIC(mod))
}

pvals_step <- 1000 %>%
  rerun(step_mod_sim(n_obs))
```

```{r sim-step-mult-plot}
# tidy
pvals_step_tidy <- pvals_step %>%
  map_df(tidy, .id = "sim") %>%
  as_tibble

# glance
pvals_step_glance <- pvals_step %>%
  map_df(glance, .id = "sim") %>%
  as_tibble

# plot of k
n_k <- pvals_step_tidy %>%
  count(sim) %>%
  count(n) %>%
  # remove intercept
  mutate(n = n - 1)

ggplot(n_k, aes(n, nn)) +
  geom_col() +
  labs(title = "Number of times k variables were selected",
       x = expression(k),
       y = NULL)

# distribution of model fit metrics
pvals_step_glance %>%
  select(r.squared, p.value) %>%
  gather(stat, val) %>%
  ggplot(aes(fct_rev(stat), val)) +
  geom_hline(yintercept = 0.05) +
  geom_boxplot() +
  scale_x_discrete(labels = c(expression(R^2), expression(p))) +
  labs(title = expression(paste("Distribution of ", R^2, " and p-values after variable selection")),
       subtitle = "p-values from F-test",
       x = NULL,
       y = NULL)
```

## Finding p-values without trying

![](https://espnfivethirtyeight.files.wordpress.com/2015/08/truth-vigilantes-soccer-calls2.png?quality=90&strip=info&w=1024&ssl=1)

----

[![](https://imgs.xkcd.com/comics/significant.png)](https://xkcd.com/882/)

## Article critique

* [Beall, A. T., & Tracy, J. L. (2013). Women are more likely to wear red or pink at peak fertility. *Psychological Science*, 0956797613476045.](http://journals.sagepub.com.proxy.uchicago.edu/doi/abs/10.1177/0956797613476045)
* ["Too Good to Be True" by Andrew Gelman. *Slate*.](http://www.slate.com/articles/health_and_science/science/2013/07/statistics_and_psychology_multiple_comparisons_give_spurious_results.html)
* ["Response by Jessica Tracy and Alec Beall to my critique of the methods in their paper, 'Women Are More Likely to Wear Red or Pink at Peak Fertility'" by Andrew Gelman.](http://andrewgelman.com/2013/07/31/response-by-jessica-tracy-and-alec-beall-to-my-criticism-of-their-paper/)

## Preventing false discovery

* Cross-validation
* p-value correction
* Pre-registration

## Corrected p-values

* Family-wise error rate (FWER)
* Bonferroni correction

## Bonferroni correction {.scrollable}

```{r sim-norm-null}
sim_norm_null <- 1000 %>%
  rerun(rnorm(n_obs)) %>%
  map(~ t.test(x = .x, mu = 0)) %>%
  map_dbl(~ .x$p.value) %>%
  as_tibble %>%
  mutate(sig = value < .05)

mean(sim_norm_null$value)

ggplot(sim_norm_null, aes(value, fill = sig)) +
  geom_histogram(binwidth = .025, boundary = 0) +
  labs(title = "Distribution of p-values for single test",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## Bonferroni correction {.scrollable}

```{r sim-norm-mult}
sim_norm_mult <- 1000 %>%
  rerun(5 %>%
          rerun(rnorm(n_obs)) %>%
          map(~ t.test(x = .x, mu = 0)) %>%
          map_dbl(~ .x$p.value) %>%
          as_tibble %>%
          mutate(sig = value < .05)) %>%
  bind_rows(.id = "sim") %>%
  group_by(sim) %>%
  rename(raw = value) %>%
  mutate(correct = raw < (.05 / n()))

sim_norm_mult %>%
  summarize(sig = any(raw < .05)) %>%
  ungroup %>%
  summarize(mean(sig))
  
sim_norm_mult %>%
  filter(raw == min(raw)) %>%
  ggplot(aes(raw, fill = sig)) +
  geom_histogram(binwidth = .01, boundary = 0) +
  labs(title = "Distribution of p-values for multiple tests",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## Bonferroni correction {.scrollable}

```{r bonferroni}
sim_norm_mult %>%
  summarize(sig = any(correct)) %>%
  ungroup %>%
  summarize(mean(sig))

sim_norm_mult %>%
  filter(raw == min(raw)) %>%
  ggplot(aes(raw, fill = correct)) +
  geom_histogram(binwidth = .01, boundary = 0) +
  labs(title = "Distribution of p-values for multiple tests",
       subtitle = "With Bonferroni correction",
       x = expression(P),
       y = NULL) +
  theme(legend.position = "none")
```

## Pre-registration of research design

* What it is
* Benefits
* Concerns
