---
title: "Statistical learning: resampling methods"
author: |
  | MACS 30500
  | University of Chicago
date: "February 20, 2017"
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

library(tidyverse)
library(modelr)
library(here)
library(broom)
library(rcfss)
theme_set(theme_minimal(base_size = 18))

options(digits = 3)
```

## Assessing model accuracy

* Goodness of fit
* Which method works best?
* Which model specification works best?
* What it does not do
* Metrics for model fit

## Coefficient of determination

$$R^2 = \frac{\text{RegSS}}{\text{TSS}}$$

$$R^2 = \frac{\text{TSS} - \text{RSS}}{\text{TSS}}$$

$$R^2 = \frac{\sum_{i = 1}^{N} (Y_i - \bar{Y}_i)^2 - \sum_{i = 1}^{N} (Y_i - \hat{Y}_i)^2}{\sum_{i = 1}^{N} (Y_i - \bar{Y}_i)^2}$$

$$R^2 = \frac{\sum_{i = 1}^{N} (\hat{Y}_i - \bar{Y}_i)^2}{\sum_{i = 1}^{N} (Y_i - \bar{Y}_i)^2}$$

## Coefficient of determination

```{r r-squared}
dist1 <- sim1 %>% 
  mutate(
    dodge = rep(c(-1, 0, 1) / 20, 10),
    x1 = x + dodge,
    pred = 7 + x1 * 1.5
  )

ggplot(dist1, aes(x1, y)) + 
  geom_abline(aes(color = "TSS"), intercept = 7, slope = 1.5) +
  geom_hline(aes(color = "RegSS"), yintercept = mean(dist1$y), color = "grey40", linetype = 2) +
  geom_point(color = "grey40") +
  geom_linerange(aes(ymin = y, ymax = pred, color = "TSS")) +
  geom_linerange(aes(ymin = pred, ymax = mean(y), color = "RegSS"), linetype = 2) +
  labs(title = expression(R^2),
       color = NULL)
```

## Mean squared error

$$MSE = \frac{1}{n} \sum_{i = 1}^{n}{(y_i - \hat{f}(x_i))^2}$$

* $y_i =$ the observed response value for the $i$th observation
* $\hat{f}(x_i) =$ the predicted response value for the $i$th observation given by $\hat{f}$
* $n =$ the total number of observations

## `Auto` dataset

```{r auto}
library(ISLR)

Auto <- Auto %>%
  tbl_df()
```

```{r auto_plot, dependson="auto"}
ggplot(Auto, aes(horsepower, mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

## `Auto` dataset

```{r auto_plot_lm, dependson="auto"}
# linear model
auto_lm <- lm(mpg ~ horsepower, data = Auto)

# quadratic model
auto_lm2 <- lm(mpg ~ horsepower + I(horsepower^2), data = Auto)

# generate predicted values plot
Auto %>%
  gather_predictions(auto_lm, auto_lm2) %>%
  mutate(model = factor(model, levels = c("auto_lm", "auto_lm2"),
                        labels = c("horsepower", "horsepower^2"))) %>%
  ggplot(aes(horsepower)) +
  geom_point(aes(y = mpg), alpha = .5) +
  geom_line(aes(y = pred, color = model), size = 1) +
  labs(x = "Horsepower",
       y = "MPG",
       color = "Model")
```

## MSE of `Auto` models

```{r mse-function}
mse <- function(model, data) {
  x <- modelr:::residuals(model, data)
  mean(x ^ 2, na.rm = TRUE)
}
```

```{r mse, dependson="auto_split", echo = TRUE}
mse(auto_lm, Auto)    # linear model
mse(auto_lm2, Auto)   # quadratic model
```

## Error rate

$$\frac{1}{n} \sum_{n = 1}^{n} I(y_i \neq \hat{y}_i)$$

## Error rate for survival model

```{r titanic_data, message = FALSE}
library(titanic)
titanic <- titanic_train %>%
  as_tibble()
```

```{r age_woman_cross}
survive_age_woman_x <- glm(Survived ~ Age * Sex, data = titanic,
                           family = binomial)
summary(survive_age_woman_x)
```

```{r accuracy_age_gender_x_test_set, dependson="age_woman_cross", message = FALSE}
x_accuracy <- titanic %>%
  add_predictions(survive_age_woman_x) %>%
  mutate(pred = logit2prob(pred),
         prob = pred,
         pred = as.numeric(pred > .5))

mean(x_accuracy$Survived != x_accuracy$pred, na.rm = TRUE)
```

## Training vs. test data

* Use training data to estimate model
* Use test data to evaluate model
* Why not use the same data to estimate and evaluate?

## Test MSE

$$MSE_{\text{Test}} = \frac{1}{n} \sum_{j = 1}^{n}{(y_j - \hat{f}(x_j))^2}$$

* Optimize test MSE, not training MSE

## Simulation of training vs. test MSE

```{r sim-mse}
sim_mse <- data_frame(X = runif(50, 0, 10),
                      Y = 3 + .05 * X + .05 * X^2 + .05 * X^3 + rnorm(50, 0, 4))

# linear model
sim_mse_1 <- lm(Y ~ poly(X, 1), data = sim_mse)

# third-order poly
sim_mse_3 <- lm(Y ~ poly(X, 3), data = sim_mse)

# twenty-order poly
sim_mse_10 <- lm(Y ~ poly(X, 10), data = sim_mse)

# add predictions and plot
sim_mse %>%
  gather_predictions(sim_mse_1, sim_mse_3, sim_mse_10) %>%
  mutate(model = factor(model, levels = c("sim_mse_1", "sim_mse_3", "sim_mse_10"),
                        labels = c("X^1", "X^3", "X^10"))) %>%
  ggplot(aes(X)) +
  geom_point(aes(y = Y)) +
  geom_line(aes(y = pred, color = model)) +
  scale_color_discrete(labels = c(expression(X^1), expression(X^3), expression(X^10))) +
  labs(color = "Model") +
  theme(legend.text.align = 0)
```

## Simulation of training vs. test MSE

```{r sim-mse-train}
data_frame(terms = c(1, 3, 10),
                           model = list(sim_mse_1, sim_mse_3, sim_mse_10)) %>%
  mutate(mse = map_dbl(model, mse, data = sim_mse)) %>%
  select(-model) %>%
  knitr::kable(caption = "Training MSEs",
               col.names = c("Highest-order term", "MSE"))
```

## New draw from DGP {.scrollable}

```{r sim-mse-test}
# simulate test data
sim_mse_test <- data_frame(X = runif(50, 0, 10),
                      Y = 3 + .05 * X + .05 * X^2 + .05 * X^3 + rnorm(50, 0, 4))

# draw graph with new points and original models
sim_mse_test %>%
  gather_predictions(sim_mse_1, sim_mse_3, sim_mse_10) %>%
  mutate(model = factor(model, levels = c("sim_mse_1", "sim_mse_3", "sim_mse_10"),
                        labels = c("X^1", "X^3", "X^10"))) %>%
  ggplot(aes(X)) +
  geom_point(aes(y = Y)) +
  geom_line(aes(y = pred, color = model)) +
  scale_color_discrete(labels = c(expression(X^1), expression(X^3), expression(X^10))) +
  labs(color = "Original\nmodel") +
  theme(legend.text.align = 0)

# test set MSE
data_frame(terms = c(1, 3, 10),
                           model = list(sim_mse_1, sim_mse_3, sim_mse_10)) %>%
  mutate(mse = map_dbl(model, mse, data = sim_mse_test)) %>%
  select(-model) %>%
  knitr::kable(caption = "Training MSEs",
               col.names = c("Highest-order term", "MSE"))
```

## Resampling methods

* Repeatedly drawing from the original sample to obtain additional information about your model
* Why do it

## Validation set

* Randomly split data into training and test set
* Estimate model using training set
* Calculate fit metric using test set

## Validation set for classification

```{r titanic-test-mse}
titanic_split <- resample_partition(titanic, c(test = 0.3, train = 0.7))

train_model <- glm(Survived ~ Age * Sex, data = titanic_split$train,
                   family = binomial)
tidy(train_model)

x_train_accuracy <- titanic_split$train %>%
  tbl_df() %>%
  add_predictions(train_model) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

x_test_accuracy <- titanic_split$test %>%
  tbl_df() %>%
  add_predictions(train_model) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

train_err <- mean(x_train_accuracy$Survived != x_train_accuracy$pred, na.rm = TRUE)
test_err <- mean(x_test_accuracy$Survived != x_test_accuracy$pred, na.rm = TRUE)
```

* Training error rate: `r train_err`
* Test error rate: `r test_err`

## Regression

```{r auto_split}
set.seed(1234)

auto_split <- resample_partition(Auto, c(test = 0.5, train = 0.5))
auto_train <- auto_split$train %>%
  tbl_df()
auto_test <- auto_split$test %>%
  tbl_df()
```

```{r mse_poly, dependson="auto_split"}
auto_poly_results <- data_frame(terms = 1:5,
           model = map(terms, ~ glm(mpg ~ poly(horsepower, .), data = auto_train)),
           MSE = map_dbl(model, mse, data = auto_test))

ggplot(auto_poly_results, aes(terms, MSE)) +
  geom_line() +
  labs(title = "Comparing quadratic linear models",
       subtitle = "Using validation set",
       x = "Highest-order polynomial",
       y = "Mean Squared Error")
```

## Drawbacks to validation sets

```{r auto_variable_mse}
mse_variable <- function(Auto){
  auto_split <- resample_partition(Auto, c(test = 0.5, train = 0.5))
  auto_train <- auto_split$train %>%
    tbl_df()
  auto_test <- auto_split$test %>%
    tbl_df()
  
  results <- data_frame(terms = 1:5,
                        model = map(terms,
                                    ~ glm(mpg ~ poly(horsepower, .),
                                          data = auto_train)),
                        MSE = map_dbl(model, mse, data = auto_test))
  
  return(results)
}

rerun(10, mse_variable(Auto)) %>%
  bind_rows(.id = "id") %>%
  ggplot(aes(terms, MSE, color = id)) +
  geom_line() +
  labs(title = "Variability of MSE estimates",
       subtitle = "Using the validation set approach",
       x = "Degree of Polynomial",
       y = "Mean Squared Error") +
  theme(legend.position = "none")
```

## Leave-one-out cross-validation

$$CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n}{MSE_i}$$

## LOOCV in linear regression

```{r loocv-data, dependson="Auto"}
loocv_data <- crossv_kfold(Auto, k = nrow(Auto))
```

```{r loocv, dependson="Auto"}
loocv_models <- map(loocv_data$train, ~ lm(mpg ~ horsepower, data = .))
loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
```

```{r loocv_poly, dependson="Auto"}
cv_error <- vector("numeric", 5)
terms <- 1:5

for(i in terms){
  loocv_models <- map(loocv_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
  loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
  cv_error[[i]] <- mean(loocv_mse)
}

cv_mse <- data_frame(terms = terms,
           cv_MSE = cv_error)

ggplot(cv_mse, aes(terms, cv_MSE)) +
  geom_line() +
  labs(title = "Comparing quadratic linear models",
       subtitle = "Using LOOCV",
       x = "Highest-order polynomial",
       y = "Mean Squared Error")
```

## LOOCV in classification

```{r mse-glm}
mse.glm <- function (model, data){
  residuals.glm <- function(model, data) {
    modelr:::response(model, data) - stats::predict(model, data, type = "response")
  }
  
  x <- residuals(model, data)
  mean(x^2, na.rm = TRUE)
}
```

```{r titanic_loocv, echo = TRUE}
titanic_loocv <- crossv_kfold(titanic, k = nrow(titanic))
titanic_models <- map(titanic_loocv$train, ~ glm(Survived ~ Age * Sex, data = .,
                                               family = binomial))
titanic_mse <- map2_dbl(titanic_models, titanic_loocv$test, mse.glm)
mean(titanic_mse, na.rm = TRUE)
```

## k-fold cross-validation

$$CV_{(k)} = \frac{1}{k} \sum_{i = 1}^{k}{MSE_i}$$

* Folds
* Number of folds

## k-fold CV in linear regression

```{r 10_fold_auto}
cv10_data <- crossv_kfold(Auto, k = 10)

cv_error_fold10 <- vector("numeric", 5)
terms <- 1:5

for(i in terms){
  cv10_models <- map(cv10_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
  cv10_mse <- map2_dbl(cv10_models, cv10_data$test, mse)
  cv_error_fold10[[i]] <- mean(cv10_mse)
}
```

```{r 10_fold_auto_loocv, dependson=c("10_fold_auto","loocv_poly")}
data_frame(terms = terms,
           loocv = cv_error,
           fold10 = cv_error_fold10) %>%
  gather(method, MSE, loocv:fold10) %>%
  ggplot(aes(terms, MSE, color = method)) +
  geom_line() +
  labs(title = "MSE estimates",
       x = "Degree of Polynomial",
       y = "Mean Squared Error",
       color = "CV Method")
```

## Computation time

```{r time}
loocv <- system.time({
  cv_error <- vector("numeric", 5)
  terms <- 1:5
  
  for(i in terms){
    loocv_models <- map(loocv_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
    loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
    cv_error[[i]] <- mean(loocv_mse)
  }
})

kfoldcv <- system.time({
  cv_error_fold10 <- vector("numeric", 5)
  terms <- 1:5
  
  for(i in terms){
    cv10_models <- map(cv10_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
    cv10_mse <- map2_dbl(cv10_models, cv10_data$test, mse)
    cv_error_fold10[[i]] <- mean(cv10_mse)
  }
})
```

* LOOCV for `Auto` dataset

    ```{r loocv_time}
    loocv
    ```
    
* 10-fold CV for `Auto` dataset

    ```{r kfold_time}
    kfoldcv
    ```

## k-fold CV in logistic regression

```{r titanic_kfold, echo = TRUE}
titanic_kfold <- crossv_kfold(titanic, k = 10)
titanic_models <- map(titanic_kfold$train, ~ glm(Survived ~ Age * Sex, data = .,
                                               family = binomial))
titanic_mse <- map2_dbl(titanic_models, titanic_kfold$test, mse.glm)
mean(titanic_mse, na.rm = TRUE)
```

## The bootstrap

![](http://izquotes.com/quotes-pictures/quote-i-believe-in-pulling-yourself-up-by-your-own-bootstraps-i-believe-it-is-possible-i-saw-this-stephen-colbert-220557.jpg)

## Sampling without replacement

```{r sim-sample-noreplace}
rerun(10, sample.int(10, replace = FALSE)) %>%
  unlist %>%
  matrix(ncol = 10, byrow = TRUE)
```

## Sampling with replacement

```{r sim-sample-replace}
rerun(10, sample.int(10, replace = TRUE)) %>%
  unlist %>%
  matrix(ncol = 10, byrow = TRUE)
```

## Why use the bootstrap?

1. Make **assumptions** about the shape of the population
1. Use the **information in the sample** to learn about it

## Make assumptions

[![](../images/xkcd_assume.png)](https://www.xkcd.com/1339/)

## Use information in the sample

![](../images/sample_pop_meme.jpg)

----

![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Rockyroadicecream.jpg/800px-Rockyroadicecream.jpg)

## Simulated ice cream data

```{r ice-sim}
# simulate the sample
set.seed(1234)
mu <- 5
n_obs <- 1000
ice <- data_frame(sim = rpois(n_obs, lambda = mu))

ggplot(ice, aes(sim)) +
  geom_histogram(binwidth = 1)
```

## Poisson distribution

![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/960px-Poisson_pmf.svg.png)

## Estimate the mean and SE

```{r ice-samp-mean}
mu_samp <- mean(ice$sim)

sem <- sqrt(mu_samp / n_obs)
```

```{r ice-boot}
ice_boot <- ice %>%
  modelr::bootstrap(1000) %>%
  mutate(mean = map_dbl(strap, ~ mean(as_tibble(.)$sim, na.rm = TRUE)))
boot_sem <- sd(ice_boot$mean)
```

```{r ice-boot-plot}
ggplot(ice_boot, aes(mean)) +
  geom_histogram(binwidth = .01) +
  geom_vline(aes(xintercept = mu, color = "Population mean"), size = 1) +
  geom_vline(aes(xintercept = mu_samp, color = "Sample mean"), size = 1) +
  geom_vline(aes(xintercept = mean(ice_boot$mean),
                 color = "Bootstrapped mean"), size = 1) +
  geom_vline(aes(xintercept = mean(ice_boot$mean) + 1.96 * boot_sem,
                 color = "Bootstrapped mean"), linetype = 2) +
  geom_vline(aes(xintercept = mean(ice_boot$mean) - 1.96 * boot_sem,
                 color = "Bootstrapped mean"), linetype = 2) +
  geom_vline(aes(xintercept = mu_samp + 1.96 * sem, color = "Sample mean"),
             linetype = 2) +
  geom_vline(aes(xintercept = mu_samp - 1.96 * sem, color = "Sample mean"),
             linetype = 2) +
  scale_color_manual(name = NULL, breaks = c("Population mean", "Sample mean",
                                             "Bootstrapped mean"),
                     values = c("blue", "green", "orange")) +
  labs(x = "Bootstrapped sample mean",
       y = "Count")
```

## New simulation of data

```{r ice-sim2}
# simulate the sample
set.seed(113)
ice2 <- data_frame(sim = c(rpois(n_obs / 2, lambda = mu),
                           round(runif(n_obs / 2, min = 0, max = 10))))

# plot the sample distribution
ggplot(ice2, aes(sim)) +
  geom_histogram(binwidth = 1)
```

## New comparison

```{r ice-sim2-2}
# calculate sample mean and standard error
mu2_samp <- mean(ice2$sim)
sem2 <- sqrt(mu2_samp / n_obs)

# calculate the bootstrap
ice2_boot <- ice2 %>%
  modelr::bootstrap(1000) %>%
  mutate(mean = map_dbl(strap, ~ mean(as_tibble(.)$sim, na.rm = TRUE)))
boot2_sem <- sd(ice2_boot$mean)

# plot the bootstrapped distribution
ggplot(ice2_boot, aes(mean)) +
  geom_histogram(binwidth = .01) +
  geom_vline(aes(xintercept = mu, color = "Population mean"), size = 1) +
  geom_vline(aes(xintercept = mu2_samp, color = "Sample mean"), size = 1) +
  geom_vline(aes(xintercept = mean(ice2_boot$mean),
                 color = "Bootstrapped mean"), size = 1) +
  geom_vline(aes(xintercept = mean(ice2_boot$mean) + 1.96 * boot2_sem,
                 color = "Bootstrapped mean"), linetype = 2) +
  geom_vline(aes(xintercept = mean(ice2_boot$mean) - 1.96 * boot2_sem,
                 color = "Bootstrapped mean"), linetype = 2) +
  geom_vline(aes(xintercept = mu2_samp + 1.96 * sem2, color = "Sample mean"),
             linetype = 2) +
  geom_vline(aes(xintercept = mu2_samp - 1.96 * sem2, color = "Sample mean"),
             linetype = 2) +
  scale_color_manual(name = NULL, breaks = c("Population mean", "Sample mean",
                                             "Bootstrapped mean"),
                     values = c("blue", "green", "orange")) +
  labs(x = "Bootstrapped sample mean",
       y = "Count")
```

## Estimating the accuracy of a linear regression model

$$\widehat{s.e.}(\hat{\beta}_j) = \sqrt{\hat{\sigma}^{2} (X^{T}X)^{-1}_{jj}}$$

----

```{r auto-boot}
# plot the data and model
ggplot(Auto, aes(horsepower, mpg)) +
  geom_point() +
  geom_smooth(method = "lm")
```

## Comparison of estimates

```{r auto-boot-2}
# traditional parameter estimates and standard errors
auto_lm <- lm(mpg ~ horsepower, data = Auto)
tidy(auto_lm) %>%
  knitr::kable(caption = "Traditional estimates")

# bootstrapped estimates of the parameter estimates and standard errors
auto_boot <- Auto %>%
  modelr::bootstrap(1000) %>%
  mutate(model = map(strap, ~ lm(mpg ~ horsepower, data = .)),
         coef = map(model, tidy))

auto_boot %>%
  unnest(coef) %>%
  group_by(term) %>%
  summarize(est.boot = mean(estimate),
            se.boot = sd(estimate, na.rm = TRUE)) %>%
  knitr::kable(caption = "Bootstrap estimates")
```

## Comparison of estimates$^2$

```{r auto-boot-sq}
# traditional parameter estimates and standard errors
auto2_lm <- lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
tidy(auto2_lm) %>%
  knitr::kable(caption = "Traditional estimates")

# bootstrapped estimates of the parameter estimates and standard errors
auto2_boot <- Auto %>%
  modelr::bootstrap(1000) %>%
  mutate(model = map(strap, ~ lm(mpg ~ horsepower + I(horsepower^2), data = .)),
         coef = map(model, tidy))

auto2_boot %>%
  unnest(coef) %>%
  group_by(term) %>%
  summarize(est.boot = mean(estimate),
            se.boot = sd(estimate, na.rm = TRUE)) %>%
  knitr::kable(caption = "Bootstrap estimates")
```


