---
date: "2018-09-09T00:00:00-05:00"
draft: false
title: "R for Data Science"
subtitle: "Exercise answer key"
type: post
aliases: "/r4da_solutions.html"
---

```{r setup, include = FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618  # 1 / phi
#  fig.show = "hold"
)
```

This is a work-in-progress answer key for the exercises in Hadley Wickham's [R for Data Science](http://r4ds.had.co.nz/). For many questions, there is more than one correct answer. This is simply what I came up with, attempting to limit myself to only using operations and functions the reader has seen in previous chapters.

> See an error or want to add an answer? [Submit a pull request.](https://github.com/uc-cfss/uc-cfss.github.io/pulls)

# Load prerequisites

```{r prereq}
library(tidyverse)
```

# 3 Data visualization

## 3.2.4 Exercises

1.  Run `ggplot(data = mpg)` what do you see?

    ```{r}
    ggplot(data = mpg)
    ```

1.  How many rows are in `mtcars`? How many columns?

    ```{r}
    # one approach
    nrow(mtcars)
    ncol(mtcars)
    
    # another approach
    dim(mtcars)
    ```

1.  What does the `drv` variable describe? Read the help for `?mpg` to find
    out.
    
    `drv` indicates whether the vehicle is front-wheel drive, rear wheel drive, or 4 wheel drive.
    
1.  Make a scatterplot of `hwy` vs `cyl`.

    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = hwy, y = cyl))
    ```
    
1.  What happens if you make a scatterplot of `class` vs `drv`. Why is
    the plot not useful?
    
    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = class, y = drv))
    ```
    
    The variables are both categorical, so the points on the plot overlap with one another.

## 3.3.1 Exercises

1.  What's gone wrong with this code? Why are the points not blue?

    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy, color = "blue"))
    ```
    
    Because the `color` argument was set within `aes()`, not `geom_point()`.
    
    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy), color = "blue")
    ```
    
1.  Which variables in `mpg` are categorical? Which variables are continuous? 
    (Hint: type `?mpg` to read the documentation for the dataset). How
    can you see this information when you run `mpg`?
    
    * Categorical - `manufacturer`, `model`, `trans`, `drv`, `fl`, `class`
    * Continuous - `displ`, `cyl`, `cty`, `hwy`
    * Categorical variables are type `chr`, whereas continuous variables are type `dbl` or `int`
    
    ```{r}
    mpg
    ```

1.  Map a continuous variable to `color`, `size`, and `shape`. How do
    these aesthetics behave differently for categorical vs. continuous
    variables?
    
    ```{r error = TRUE}
    # color
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, color = cty))
    
    # size
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, size = cty))
    
    # shape
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, shape = cty))
    ```
    
    For these aesthetics, continuous variables are visualized on a spectrum (see the color plot with the continuous color palette), whereas categorical variables are binned into discrete categories, like this:
    
    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, color = class))
    ```
    
1.  What happens if you map the same variable to multiple aesthetics? 

    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, color = cty, size = cty))
    ```
    
    Both aesthetics are implemented, and multiple legends are generated.

1.  What does the `stroke` aesthetic do? What shapes does it work with?
    (Hint: use `?geom_point`)
    
    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy), stroke = 3, shape = 21)
    ```
    
    `stroke` adjusts the thickness of the border for shapes that can take on different colors both inside and outside. [It only works for shapes 21-24.](http://docs.ggplot2.org/current/vignettes/ggplot2-specs.html)
    
    ```{r shapes, echo = FALSE}
    shapes <- data.frame(
      shape = c(0:19, 22, 21, 24, 23, 20),
      x = 0:24 %/% 5,
      y = -(0:24 %% 5)
      )
  
    ggplot(shapes, aes(x, y)) +
      geom_point(aes(shape = shape), size = 5, fill = "red") +
      geom_text(aes(label = shape), hjust = 0, nudge_x = 0.15) +
      scale_shape_identity() +
      expand_limits(x = 4.1) +
      scale_x_continuous(NULL, breaks = NULL) +
      scale_y_continuous(NULL, breaks = NULL)
    ```
    
1.  What happens if you map an aesthetic to something other than a variable 
    name, like `aes(colour = displ < 5)`?
    
    ```{r}
    ggplot(data = mpg) +
      geom_point(mapping = aes(x = displ, y = hwy, color = displ < 5))
    ```
    
    R executes the code and creates a temporary variable containing the results of the operation. Here, the new variable takes on a value of `TRUE` if the engine displacement is less than 5 or `FALSE` if the engine displacement is more than or equal to 5.

## 3.5.1 Exercises

1.  What happens if you facet on a continuous variable?
    
    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = drv, y = cyl)) +
      facet_wrap(~ displ)
    ```
    
    Your graph will not make much sense. R will try to draw a separate facet for each unique value of the continuous variable. If you have too many unique values, you may crash R.

1.  What do the empty cells in plot with `facet_grid(drv ~ cyl)` mean?
    How do they relate to this plot?
    
    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = drv, y = cyl))
    ```

    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = drv, y = cyl)) +
      facet_grid(drv ~ cyl)
    ```
    
    Empty cells mean there are no observations in the data that have that unique combination of values. For instance, in this plot we can determine that there are no vehicles with 5 cylinders that are also 4 wheel drive vehicles. The plot is similar to the original one, just that each facet only appears to have a single data point.
    
1.  What plots does the following code make? What does `.` do?

    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      facet_grid(drv ~ .)
    
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      facet_grid(. ~ cyl)
    ```
    
    `.` acts a placeholder for no variable. In `facet_grid()`, this results in a plot faceted on a single dimension (1 by $N$ or $N$ by 1) rather than an $N$ by $N$ grid.

1.  Take the first faceted plot in this section:

    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) + 
      facet_wrap(~ class, nrow = 2)
    ```
    
    What are the advantages to using faceting instead of the colour aesthetic?
    What are the disadvantages? How might the balance change if you had a 
    larger dataset?
    
    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy, color = class))
    ```
    
    Faceting splits the data into separate grids and better visualizes trends within each individual facet. The disadvantage is that by doing so, it is harder to visualize the overall relationship across facets. The color aesthetic is fine when your dataset is small, but with larger datasets points may begin to overlap with one another. In this situation with a colored plot, jittering may not be sufficient because of the additional color aesthetic.
    
1.  Read `?facet_wrap`. What does `nrow` do? What does `ncol` do? What other
    options control the layout of the individual panels? Why doesn't
    `facet_grid()` have `nrow` and `ncol` variables?
    
    1. `nrow` sets how many rows the faceted plot will have.
    1. `ncol` sets how many columns the faceted plot will have.
    1. `as.table` determines the starting facet to begin filling the plot, and `dir` determines the starting direction for filling in the plot (horizontal or vertical).

1.  When using `facet_grid()` you should usually put the variable with more
    unique levels in the columns. Why?
    
    This will extend the plot vertically, where you typically have more viewing space. If you extend it horizontally, the plot will be compressed and harder to view.
    
    ```{r}
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      facet_grid(trans ~ drv)

    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      facet_grid(drv ~ trans)
    ```

## 3.6.1 Exercises

1.  What geom would you use to draw a line chart? A boxplot? 
    A histogram? An area chart?
    
    * Line chart - `geom_line()`
    * Boxplot - `geom_boxplot()`
    * Histogram - `geom_histogram()`
    * Area chart - `geom_area()`

1.  Run this code in your head and predict what the output will look like.
    Then, run the code in R and check your predictions.
    
    ```{r}
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + 
      geom_point() + 
      geom_smooth(se = FALSE)
    ```

1.  What does `show.legend = FALSE` do?  What happens if you remove it?  
    Why do you think I used it earlier in the chapter?
    
    It removes the legend. The aesthetics are still mapped and plotted, but the key is removed from the graph. I don't know why used it earlier because he actually did not.

1.  What does the `se` argument to `geom_smooth()` do?

    It determines whether or not to draw a confidence interval around the smoothing line.

1.  Will these two graphs look different? Why/why not?

    ```{r}
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_point() + 
      geom_smooth()
    
    ggplot() + 
      geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
    ```
    
    No because they use the same data and mapping settings. The only difference is that by storing it in the `ggplot()` function, it is automatically reused for each layer.

1.  Recreate the R code necessary to generate the following graphs.
    
    ```{r fig.width = 3, fig.align = "default", message = FALSE}
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_point() + 
      geom_smooth(se = FALSE)
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_smooth(aes(group = drv), se = FALSE) +
      geom_point()
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + 
      geom_point() + 
      geom_smooth(se = FALSE)
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_point(aes(color = drv)) + 
      geom_smooth(se = FALSE)
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_point(aes(color = drv)) +
      geom_smooth(aes(linetype = drv), se = FALSE)
    ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
      geom_point(size = 4, colour = "white") + 
      geom_point(aes(colour = drv))
    ```
    
## 3.8.1 Exercises

1.  What is the default geom associated with `stat_summary()`? How could
    you rewrite the previous plot to use that geom function instead of the 
    stat function?
    
    The default geom is `geom_pointrange()`. Rewritten, we could use:
    
    ```{r}
    ggplot(data = diamonds) +
      geom_pointrange(mapping = aes(x = cut, y = depth),
                      stat = "summary",
                      fun.ymin = min,
                      fun.ymax = max,
                      fun.y = median)
    ```

1.  What does `geom_col()` do? How is it different to `geom_bar()`?

    `geom_bar()` uses the `stat_count()` statistical transformation to draw the bar graph. `geom_col()` assumes the values have already been transformed to the appropriate values. `geom_bar(stat = "identity")` and `geom_col()` are equivalent.

1.  Most geoms and stats come in pairs that are almost always used in 
    concert. Read through the documentation and make a list of all the 
    pairs. What do they have in common?

1.  What variables does `stat_smooth()` compute? What parameters control
    its behaviour?
    
    `stat_smooth()` calculates four variables:
        
    1. `y` - predicted value
    1. `ymin` - lower pointwise confidence interval around the mean
    1. `ymax` - upper pointwise confidence interval around the mean
    1. `se` - standard error
    
    See `?stat_smooth` for more details on the specific parameters. Most importantly, `method` controls the smoothing method to be employed, `se` determines whether confidence interval should be plotted, and `level` determines the level of confidence interval to use.

1.  In our proportion bar chart, we need to set `group = 1`. Why? In other
    words what is the problem with these two graphs?
    
    ```{r}
    ggplot(data = diamonds) + 
      geom_bar(mapping = aes(x = cut, y = stat(prop)))
    ggplot(data = diamonds) + 
      geom_bar(mapping = aes(x = cut, fill = color, y = stat(prop)))
    ```
    
    If we fail to set `group = 1`, the proportions for each cut are calculated using the complete dataset, rather than each subset of `cut`. Instead, we want the graphs to look like this:

    ```{r}
    ggplot(data = diamonds) + 
      geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))
    ggplot(data = diamonds) + 
      geom_bar(mapping = aes(x = cut, fill = color, y = stat(prop), group = 1))
    ```

## 3.8.1 Exercises

1.  What is the problem with this plot? How could you improve it?

    ```{r}
    ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + 
      geom_point()
    ```
    
    Many of the data points overlap. We can jitter the points by adding some slight random noise, which will improve the overall visualization.

    ```{r}
    ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + 
      geom_jitter()
    ``` 

1.  What parameters to `geom_jitter()` control the amount of jittering?

    `width` and `height`.

1.  Compare and contrast `geom_jitter()` with `geom_count()`.

    ```{r}
    ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + 
      geom_jitter()

    ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + 
      geom_count()
    ```
    
    Rather than adding random noise, `geom_count()` counts the number of observations at each location, then maps the count to point area. It makes larger points the more observations are located at that area, so the number of visible points is equal to `geom_point()`.

1.  What's the default position adjustment for `geom_boxplot()`? Create
    a visualisation of the `mpg` dataset that demonstrates it.
    
    The default position adjustment is `position_dodge()`.
    
    ```{r}
    ggplot(data = mpg, mapping = aes(x = class, y = hwy, color = drv)) + 
      geom_boxplot(position = "dodge")
    ```

## 3.9.1 Exercises

1.  Turn a stacked bar chart into a pie chart using `coord_polar()`.

    ```{r}
    ggplot(data = mpg, mapping = aes(x = factor(1), fill = class)) +
      geom_bar(width = 1) +
      coord_polar(theta = "y")
    ```

1.  What does `labs()` do? Read the documentation.

    `labs()` adds labels to the graph. You can add a title, subtitle, and a label for the $x$ and $y$ axes, as well as a caption.

1.  What's the difference between `coord_quickmap()` and `coord_map()`?

    `coord_map()` projects a portion of the earth (a three-dimensional object) onto a flat (two-dimensional) plane. `coord_map()` does not preserve straight lines and therefore is computationally intensive; `coord_quickmap()` preserves straight lines and is therefore faster to draw (though less accurate).

1.  What does the plot below tell you about the relationship between city
    and highway mpg? Why is `coord_fixed()` important? What does 
    `geom_abline()` do?
    
    ```{r, fig.asp = 1}
    ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
      geom_point() + 
      geom_abline() +
      coord_fixed()
    ```
    
    The relationships is approximately linear, though overall cars have slightly better highway mileage than city mileage. But using `coord_fixed()`, the plot draws equal intervals on the $x$ and $y$ axes so they are directly comparable. `geom_abline()` draws a line that, by default, has an intercept of 0 and slope of 1. This aids us in our discovery that automobile gas efficiency is on average slightly higher for highways than city driving, though the slope of the relationship is still roughly 1-to-1.
    
# 4 Workflow: basics

## 4.4 Practice

1.  Why does this code not work?

    ```{r, error = TRUE}
    my_variable <- 10
    my_varıable
    ```
    
    The second line has a typo. It should be `my_variable`, not `my_varıable`.
    
1.  Tweak each of the following R commands so that they run correctly:

    ```{r, error = TRUE}
    library(tidyverse)
    
    # incorrect
    ggplot(dota = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy))

    # correct
    ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy))
    
    # incorrect
    fliter(mpg, cyl = 8)
    filter(diamond, carat > 3)
    
    # correct
    filter(mpg, cyl == 8)
    filter(diamonds, carat > 3)
    ```
    
1.  Press Alt + Shift + K. What happens? How can you get to the same place
    using the menus?
    
    The keyboard shortcuts help display appears. To access it from the menus, go to *Help* > *Keyboard Shortcuts Help*


# 5 Data transformation

## 5.7.1 Exercises

1.  Find all flights that

    1. Had an arrival delay of two or more hours
    
        ```{r}
        library(nycflights13)
        filter(flights, arr_delay >= 120)
        ```
    
    1. Flew to Houston (`IAH` or `HOU`)
    
        ```{r}
        filter(flights, dest == "IAH" | dest == "HOU")
        ```
    
    1. Were operated by United, American, or Delta
    
        ```{r}
        filter(flights, carrier == "UA" |
                 carrier == "AA" |
                 carrier == "DL")
        ```
    
    1. Departed in summer (July, August, and September)
    
        ```{r}
        filter(flights, month >= 7, month <= 9)
        ```
    
    1. Arrived more than two hours late, but didn't leave late
    
        ```{r}
        filter(flights, arr_delay >= 120, dep_delay <= 0)
        ```
    
    1. Were delayed by at least an hour, but made up over 30 minutes in flight
    
        ```{r}
        filter(flights, dep_delay >= 60, dep_delay - arr_delay >= 30)
        ```
    
    1. Departed between midnight and 6am (inclusive)
    
        ```{r}
        filter(flights, dep_time >=0, dep_time <= 600)
        ```

1.  Another useful dplyr filtering helper is `between()`. What does it do?
    Can you use it to simplify the code needed to answer the previous 
    challenges?
    
    It is a shortcut for finding observations between two values. For example, we can simplify this code:
    
    ```{r}
    filter(flights, month >= 7, month <= 9)
    filter(flights, between(month, 7, 9))
    ```

1.  How many flights have a missing `dep_time`? What other variables are 
    missing? What might these rows represent?
    
    ```{r}
    filter(flights, is.na(dep_time))
    ```
    
    They are also missing values for arrival time and departure/arrival delay. Most likely these are scheduled flights that never flew.

1.  Why is `NA ^ 0` not missing? Why is `NA | TRUE` not missing?
    Why is `FALSE & NA` not missing? Can you figure out the general
    rule?  (`NA * 0` is a tricky counterexample!)
    
    * `NA ^ 0` - by definition anything to the 0th power is 1.
    * `NA | TRUE` - as long as one condition is `TRUE`, the result is `TRUE`. By definition, `TRUE` is `TRUE`.
    * `FALSE & NA` - `NA` indicates the absence of a value, so the conditional expression ignores it.
    * In general any operation on a missing value becomes a missing value. Hence `NA * 0` is `NA`. In conditional expressions, missing values are simply ignored.

## 5.3.1 Exercises

1.  How could you use `arrange()` to sort all missing values to the start?
    (Hint: use `is.na()`).
    
    ```{r, eval = FALSE}
    arrange(data, !is.na(.))
    ```
    
    A working example:
    
    ```{r}
    arrange(flights, !is.na(dep_time))
    ```
    
1.  Sort `flights` to find the most delayed flights. Find the flights that
    left earliest.
    
    ```{r}
    # most delayed (based on arrival)
    arrange(flights, desc(arr_delay))
    
    # left earliest
    arrange(flights, dep_delay)
    ```

1.  Sort `flights` to find the fastest flights.

    ```{r}
    arrange(flights, desc(distance / air_time))
    ```

1.  Which flights travelled the longest? Which travelled the shortest?

    ```{r}
    # longest flights by distance
    arrange(flights, desc(distance))
    
    # shortest flights by distance
    arrange(flights, distance)
    ```

## 5.4.1 Exercises

1.  Brainstorm as many ways as possible to select `dep_time`, `dep_delay`,
    `arr_time`, and `arr_delay` from `flights`.
    
    ```{r}
    select(flights, dep_time, dep_delay, arr_time, arr_delay)
    select(flights, starts_with("dep"), starts_with("arr"))
    select(flights, ends_with("delay"))
    select(flights, contains("delay"))
    ```
    
1.  What happens if you include the name of a variable multiple times in
    a `select()` call?
    
    It is included only a single time in the new data frame.
  
1.  What does the `one_of()` function do? Why might it be helpful in conjunction
    with this vector?
    
    ```{r}
    vars <- c("year", "month", "day", "dep_delay", "arr_delay")
    ```
    
    It selects any variable which matches one of the strings in the vector.
    
    ```{r}
    select(flights, one_of(vars))
    ```
    
1.  Does the result of running the following code surprise you?  How do the
    select helpers deal with case by default? How can you change that default?

    ```{r}
    select(flights, contains("TIME"))
    ```
    
    By default the select helpers ignore case. To adhere to case, set `ignore.case = FALSE` in the helper function. For example:
    
    ```{r}
    select(flights, contains("TIME", ignore.case = FALSE))
    ```

## 5.5.2 Exercises

1.  Currently `dep_time` and `sched_dep_time` are convenient to look at, but
    hard to compute with because they're not really continuous numbers. 
    Convert them to a more convenient representation of number of minutes
    since midnight.
    
    ```{r}
    transmute(flights,
           sched_dep_time = (sched_dep_time %/% 100) * 60 + sched_dep_time %% 100,
           dep_time = (dep_time %/% 100) * 60 + dep_time %% 100)
    ```
    
1.  Compare `air_time` with `arr_time - dep_time`. What do you expect to see?
    What do you see? What do you need to do to fix it?
    
    ```{r}
    flights2 <- select(flights, air_time, arr_time, dep_time)
    mutate(flights2, air_time_new = arr_time - dep_time)
    ```
    
    They are not the same because `dep_time` and `arr_time` are not measured in minutes, but are numerical representations of the time. We need to convert them to continuous numbers like above to make the correct calculation for `air_time`.
    
1.  Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you
    expect those three numbers to be related?
    
    `dep_time` should equal `sched_dep_time` $+$ `dep_delay` (after accounting for the fact that they are not stored continuously).

1.  Find the 10 most delayed flights using a ranking function. How do you want 
    to handle ties? Carefully read the documentation for `min_rank()`.
    
    ```{r}
    delayed <- mutate(flights, most_delayed = min_rank(desc(arr_delay)))
    arrange(delayed, most_delayed)
    ```
    
    I used `min_rank()` which assigns ties to the lowest rank. See [here](http://stats.stackexchange.com/questions/34008/how-does-ties-method-argument-of-rs-rank-function-work) for a detailed discussion of potential tie breaking methods.

1.  What does `1:3 + 1:10` return? Why?

    ```{r}
    1:3 + 1:10
    ```
    
    Because the two vectors are not the same length, R **recycles** the shorter one until each vector is the same length. Then R adds the first elements together, then the second elements, then the third, etc.

1.  What trigonometric functions does R provide?

    [Cosine, sine, tangent, arc-tangent, arc-sine, arc-tangent, and the two-argument arc-tangent.](https://stat.ethz.ch/R-manual/R-devel/library/base/html/Trig.html)

## 5.6.7 Exercises

1.  Brainstorm at least 5 different ways to assess the typical delay 
    characteristics of a group of flights. Consider the following scenarios:
    
    * A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of 
      the time.
      
    * A flight is always 10 minutes late.

    * A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of 
      the time.
      
    * 99% of the time a flight is on time. 1% of the time it's 2 hours late.
    
    Which is more important: arrival delay or departure delay?
    
    ```{r}
    # A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
    flights %>%
      group_by(flight) %>%
      summarize(early_15_min = sum(arr_delay <= -15, na.rm = TRUE) / n(),
                late_15_min = sum(arr_delay >= 15, na.rm = TRUE) / n()) %>%
      filter(early_15_min == 0.5,
             late_15_min == 0.5)
    
    # A flight is always 10 minutes late.
    flights %>%
      group_by(flight) %>%
      summarize(late_10 = sum(arr_delay == 10, na.rm = TRUE) / n()) %>%
      filter(late_10 == 1)
    
    # A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.
    flights %>%
      group_by(flight) %>%
      summarize(early_30_min = sum(arr_delay <= -30, na.rm = TRUE) / n(),
                late_30_min = sum(arr_delay >= 30, na.rm = TRUE) / n()) %>%
      filter(early_30_min == 0.5,
             late_30_min == 0.5)
    
    # 99% of the time a flight is on time. 1% of the time it's 2 hours late.
    flights %>%
      group_by(flight) %>%
      summarize(on_time = sum(arr_delay == 0, na.rm = TRUE) / n(),
                late_2_hours = sum(arr_delay >= 120, na.rm = TRUE) / n()) %>%
      filter(on_time == .99,
             late_2_hours == .01)
    ```
    
    Delay type importance depends on individual preference. If an individual hates waiting in the terminal for the flight to take off, then departure delay is more important. If the individual cares more about arriving at their destination on time (which I personally care more about), then arrival delay is most important.

1.  Come up with another approach that will give you the same output as 
    `not_cancelled %>% count(dest)` and 
    `not_cancelled %>% count(tailnum, wt = distance)` (without using 
    `count()`).
    
    ```{r}
    not_cancelled <- flights %>% 
      filter(!is.na(dep_delay), !is.na(arr_delay))
    
    # original
    not_cancelled %>%
      count(dest)
    
    # new
    not_cancelled %>%
      group_by(dest) %>%
      summarize(n = n())
    
    # original
    not_cancelled %>%
      count(tailnum, wt = distance)
    
    # new
    not_cancelled %>%
      group_by(tailnum) %>%
      summarize(n = sum(distance, na.rm = TRUE))
    ```

1.  Our definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)`
    ) is slightly suboptimal. Why? Which is the most important column?
    
    There are no flights which arrived but did not depart, so we can just use `!is.na(dep_delay)`.

1.  Look at the number of cancelled flights per day. Is there a pattern?
    Is the proportion of cancelled flights related to the average delay?
    
    **NOTE: I assume when the question refers to "per day", I am only grouping by `day`. Alternatively this could mean to group by calendar day, which would require grouping by `year`, `month`, and `day`.
    
    ```{r}
    flights %>%
      filter(is.na(dep_delay)) %>%
      count(day)
    
    flights %>%
      group_by(day) %>%
      summarize(prop_canceled = sum(is.na(dep_delay)) / n(),
                avg_delay = mean(dep_delay, na.rm = TRUE))
    ```

1.  Which carrier has the worst delays? Challenge: can you disentangle the
    effects of bad airports vs. bad carriers? Why/why not? (Hint: think about
    `flights %>% group_by(carrier, dest) %>% summarise(n())`)
    
    ```{r}
    # worst delays
    flights %>%
      group_by(carrier) %>%
      summarize(mean_delay = mean(arr_delay, na.rm = TRUE)) %>%
      arrange(desc(mean_delay))
    
    # challenge: bad airports vs. bad carriers
    flights %>%
      group_by(carrier, dest) %>%
      summarize(mean_delay = mean(arr_delay, na.rm = TRUE)) %>%
      group_by(carrier) %>%
      summarize(mean_delay_mad = mad(mean_delay, na.rm = TRUE)) %>%
      arrange(desc(mean_delay_mad))
    ```
    
    For the challenge, I calculated the median absolute deviation of average arrival delay by carrier and destination. Higher values indicate a larger spread in the average delays across destinations, meaning these carriers experienced more variation in average delays - for some destinations these carriers experienced longer delays, whereas some destinations arrivals were closer to on time. Lower values mean the carrier experienced similar delays across destinations. **It does not mean these carriers were on time.** It just means they were more consistent. Comparing this table to the first table of average arrival delays could disentangle the effect of bad carriers vs. bad airports.

1.  For each plane, count the number of flights before the first delay 
    of greater than 1 hour.
    
    ```{r}
    flights %>%
      group_by(tailnum) %>%
      mutate(row_num = row_number()) %>%
      filter(arr_delay > 60) %>%
      summarize(first_hour_delay = first(row_num) - 1)
    ```
    
    This uses a grouped summary operation. First I group by plane (`tailnum`), then I create a variable that defines the row number within each plane. I then filter the data to only include flights with delays longer than an hour, and use `summarize()` in conjunction with `first()` to find for each plane the `row_num` of the first flight with an 1+ hour delay. I subtract 1 from that value to count the number of flights *before the first delay*, rather than including the first flight with the hour or more delay.

1.  What does the `sort` argument to `count()` do. When might you use it?

    The `sort` argument will sort the results of `count()` in descending order of `n`. You might use this if you plan to `arrange()` the results after completing the count. This saves you a line of code.

## 5.7.1 Exercises

1.  Refer back to the table of useful mutate and filtering functions. 
    Describe how each operation changes when you combine it with grouping.

1.  Which plane (`tailnum`) has the worst on-time record?

    Here I define "on-time" as arriving within 30 minutes of the scheduled arrival time.

    ```{r}
    flights %>%
      group_by(tailnum) %>%
      summarize(prop_on_time = sum(arr_delay <= 30, na.rm = TRUE) / n(),
                mean_arr_delay = mean(arr_delay, na.rm = TRUE),
                flights = n()) %>%
      arrange(prop_on_time, desc(mean_arr_delay))
    ```

1.  What time of day should you fly if you want to avoid delays as much
    as possible?
    
    ```{r}
    flights %>%
      group_by(hour) %>%
      summarize(arr_delay = sum(arr_delay > 5, na.rm = TRUE) / n()) %>%
      ggplot(aes(x = hour, y = arr_delay)) +
      geom_col()
    ```
    
    Avoid flying in the evening to minimize your arrival delay.
    
1.  For each destination, compute the total minutes of delay. For each, 
    flight, compute the proportion of the total delay for its destination.
    
1.  Delays are typically temporally correlated: even once the problem that
    caused the initial delay has been resolved, later flights are delayed 
    to allow earlier flights to leave. Using `lag()` explore how the delay
    of a flight is related to the delay of the immediately preceding flight.
    
    ```{r}
    flights %>%
      group_by(origin) %>%
      arrange(year, month, day, hour, minute) %>%
      mutate(prev_dep_delay = lag(dep_delay)) %>%
      ggplot(aes(x = prev_dep_delay, y = dep_delay)) +
      geom_point() +
      geom_smooth()
    ```
    
1.  Look at each destination. Can you find flights that are suspiciously
    fast? (i.e. flights that represent a potential data entry error). Compute
    the air time a flight relative to the shortest flight to that destination.
    Which flights were most delayed in the air?
    
1.  Find all destinations that are flown by at least two carriers. Use that
    information to rank the carriers.

# 7 Exploratory Data Analysis

## 7.3.4 Exercises

1.  Explore the distribution of each of the `x`, `y`, and `z` variables 
    in `diamonds`. What do you learn? Think about a diamond and how you
    might decide which dimension is the length, width, and depth.
    
    ```{r}
    ggplot(diamonds, aes(x)) +
      geom_histogram()

    ggplot(diamonds, aes(y)) +
      geom_histogram()

    ggplot(diamonds, aes(z)) +
      geom_histogram()
    ```

1.  Explore the distribution of `price`. Do you discover anything unusual
    or surprising? (Hint: Carefully think about the `binwidth` and make sure
    you try a wide range of values.)
    
    ```{r}
    # default binwidth
    ggplot(diamonds, aes(price)) +
      geom_histogram()
    
    # binwidth = 100
    ggplot(diamonds, aes(price)) +
      geom_histogram(binwidth = 100) +
      scale_x_continuous(breaks = seq(0, 20000, by = 1000))
    ```

    There are far fewer diamonds priced at \$1500 compared to other price points. This is not apparent using the default number of bins.
    
1.  How many diamonds are 0.99 carat? How many are 1 carat? What
    do you think is the cause of the difference?
    
    ```{r}
    ggplot(diamonds, aes(carat)) +
      geom_histogram(binwidth = .01) +
      coord_cartesian(xlim = c(.97, 1.03))
    ```
    
    Around 1500 diamonds are $1.00$ carat, compared to around 30 or so diamonds at $.99$ carat. This could occur because prospective buyers of diamonds, if they are already willing to buy a $.99$ carat diamond will decide it is more aesthetically pleasing to say they bought a $1$ carat diamond so there is less demand for $.99$ carat diamonds.
    
1.  Compare and contrast `coord_cartesian()` vs `xlim()` or `ylim()` when
    zooming in on a histogram. What happens if you leave `binwidth` unset?
    What happens if you try and zoom so only half a bar shows?
    
    ```{r}
    # full plot
    ggplot(diamonds, aes(carat, price)) +
      geom_point() +
      geom_smooth()
    
    # xlim
    ggplot(diamonds, aes(carat, price)) +
      geom_point() +
      geom_smooth() +
      xlim(1, 3)
    
    # coord_cartesian
    ggplot(diamonds, aes(carat, price)) +
      geom_point() +
      geom_smooth() +
      coord_cartesian(xlim = c(1, 3))
    ```
    
    By using `xlim()` or `ylim()`, you remove all observations which exceed these values so they are not used to generate the plot. By using `coord_cartesian()`, those values are used to generate the plot and are merely cut off when zooming in. Note the change in the smoothing line in the `xlim()` example because it doesn't have all the data points to calculate the line.

## 7.4.1 Exercises

1.  What happens to missing values in a histogram?  What happens to missing
    values in a bar chart? Why is there a difference?
    
    ```{r}
    ggplot(flights, aes(dep_delay)) +
      geom_histogram()
    
    # change AA to NA
    flights %>%
      mutate(carrier = ifelse(carrier == "AA", NA, carrier)) %>%
      ggplot(aes(carrier)) +
      geom_bar()
    ```
    
    Histograms omit missing values, whereas bar charts draw them as a separate category. For continuous variables, like in a histogram, there is no meaningful location to draw missing values. On the far left? Far right? Middle? But for bar charts, which are used for categorical variables, you could draw them as a distinct bar; by default it can be located anywhere on the chart (conventionally it is drawn on the right side). You can override this default to completely remove missing values from the chart if you prefer.

1.  What does `na.rm = TRUE` do in `mean()` and `sum()`?

    It strips missing values before computing the statistic.

## 7.5.1.1 Exercises

1.  Use what you've learned to improve the visualisation of the departure times
    of cancelled vs. non-cancelled flights.
    
    ```{r}
    # original chart
    flights %>% 
      mutate(
        cancelled = is.na(dep_time),
        sched_hour = sched_dep_time %/% 100,
        sched_min = sched_dep_time %% 100,
        sched_dep_time = sched_hour + sched_min / 60
        ) %>%
      ggplot(mapping = aes(sched_dep_time)) + 
      geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)

    # revised chart
    flights %>% 
      mutate(
        cancelled = is.na(dep_time),
        sched_hour = sched_dep_time %/% 100,
        sched_min = sched_dep_time %% 100,
        sched_dep_time = sched_hour + sched_min / 60
        ) %>%
      ggplot(aes(x = sched_dep_time, y = stat(density), color = cancelled)) + 
      geom_freqpoly(binwidth = 1/4)
    ```

1.  What variable in the diamonds dataset is most important for predicting
    the price of a diamond? How is that variable correlated with cut?
    Why does the combination of those two relationships lead to lower quality
    diamonds being more expensive?
    
    ```{r}
    ggplot(diamonds, aes(carat, price)) +
      geom_point() +
      geom_smooth()
    ```

    Carat size is the most important predictor of price.

    ```{r}
    ggplot(diamonds, aes(cut, carat)) +
      geom_boxplot()
    ```
    
    This boxplot visualizes the relationship between cut and carat. On average, fair and good cut diamonds are larger than premium and ideal cuts. If carat size is the more dominant predictor of price, then some larger good cut diamonds will be more expensive than smaller ideal cut diamonds.

1.  Install the `ggstance` package, and create a horizontal boxplot.
    How does this compare to using `coord_flip()`?
    
    ```{r, eval = FALSE}
    install.packages("ggstance")
    ```
    
    To create a horizontal layer in `ggplot2` with `coord_flip()`, you have to supply aesthetics as if they were to be drawn vertically:
    
    ```{r}
    ggplot(diamonds, aes(cut, carat)) +
      geom_boxplot() +
      coord_flip()
    ```
    
    In `ggstance`, you supply aesthetics in their natural order:
    
    ```{r}
    library(ggstance)
    ggplot(diamonds, aes(carat, cut)) +
      geom_boxploth()
    ```

1.  One problem with boxplots is that they were developed in an era of 
    much smaller datasets and tend to display a prohibitively large
    number of "outlying values". One approach to remedy this problem is
    the letter value plot. Install the `lvplot` package, and try using
    `geom_lv()` to display the distribution of price vs cut. What
    do you learn? How do you interpret the plots?

    ```{r, eval = FALSE}
    devtools::install_github("hadley/lvplot")
    ```
    
    ```{r}
    library(lvplot)
    
    # with boxplot
    ggplot(diamonds, aes(cut, price)) +
      geom_boxplot()
    
    # with lvplot
    ggplot(diamonds, aes(cut, price)) +
      geom_lv()
    ```
    
1.  Compare and contrast `geom_violin()` with a facetted `geom_histogram()`,
    or a coloured `geom_freqpoly()`. What are the pros and cons of each 
    method?
    
    ```{r}
    # geom_violin
    ggplot(diamonds, aes(cut, price)) +
      geom_violin()
    
    # faceted geom_histogram
    ggplot(diamonds, aes(price)) +
      geom_histogram() +
      facet_grid(. ~ cut)
    
    # colored geom_freqpoly
    ggplot(diamonds, aes(price, color = cut)) +
      geom_freqpoly()
    ```

1.  If you have a small dataset, it's sometimes useful to use `geom_jitter()`
    to see the relationship between a continuous and categorical variable.
    The `ggbeeswarm` package provides a number of methods similar to 
    `geom_jitter()`. List them and briefly describe what each one does.

# 10 Tibbles

## 10.5 Exercises

1.  How can you tell if an object is a tibble? (Hint: try printing `mtcars`,
    which is a regular data frame). 
    
    ```{r}
    # data frame
    print(mtcars)
    
    # tibble
    print(as_tibble(mtcars))
    ```
    
    A data frame will print the entire contents. A tibble will only print (by default) the first 10 rows and as many columns as will fit in the console.

1.  Compare and contrast the following operations on a `data.frame` and 
    equivalent tibble. What is different? Why might the default data frame
    behaviours cause you frustration?
    
    ```{r}
    # on a data frame
    df <- data.frame(abc = 1, xyz = "a")
    df$x
    df[, "xyz"]
    df[, c("abc", "xyz")]
    
    # on a tibble
    df <- tibble(abc = 1, xyz = "a")
    df$x
    df[, "xyz"]
    df[, c("abc", "xyz")]
    ```
    
    * Tibbles never do partial matching; data frames do.
    * Subsetting tibbles using `[[` will always return a tibble; subsetting data frames using `[[` can potentially return a vector.
    
        ![](images/gump.jpg)

1.  If you have the name of a variable stored in an object, e.g. `var <- "mpg"`,
    how can you extract the reference variable from a tibble?
    
    ```{r}
    var <- "hwy"
    mpg[[var]]
    ```

1.  Practice referring to non-syntactic names in the following data frame by:

    ```{r}
    annoying <- tibble(
      `1` = 1:10,
      `2` = `1` * 2 + rnorm(length(`1`))
    )
    ```

    1.  Extracting the variable called `1`.
    
        ```{r}
        annoying$`1`
        ```

    1.  Plotting a scatterplot of `1` vs `2`.

        ```{r}
        ggplot(annoying, aes(`1`, `2`)) +
          geom_point()
        ```

    1.  Creating a new column called `3` which is `2` divided by `1`.
        
        ```{r}
        (annoying <- mutate(annoying, `3` = `2` / `1`))
        ```

    1.  Renaming the columns to `one`, `two` and `three`.

        ```{r}
        rename(annoying,
               one = `1`,
               two = `2`,
               three = `3`)
        ```

1.  What does `tibble::enframe()` do? When might you use it?

    `enframe()` is a helper function that converts named atomic vectors or lists to two-column data frames. You might use it if you have data stored in a named vector and you want to add it to a data frame and preserve both the name attribute and the actual value.
    
    ```{r}
    enframe(c(a = 5, b = 7))
    ```

1.  What option controls how many additional column names are printed
    at the footer of a tibble?
    
    `getOption("tibble.max_extra_cols")`

## Session Info

```{r child = here::here("R", "_session-info.Rmd")}
```
