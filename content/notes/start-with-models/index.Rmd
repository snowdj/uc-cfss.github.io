---
title: "Build a linear model"
date: 2019-03-01

type: docs
toc: true
draft: false
categories: ["stat-learn"]

menu:
  notes:
    parent: Machine learning
    weight: 2
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r load, cache = FALSE, message = FALSE, warning = FALSE}
library(tidymodels)
library(tidyverse)
library(rcfss)
library(rstanarm)
library(broom.mixed)

set.seed(123)
theme_set(theme_minimal())
```

## Introduction {#intro}

There are several different approaches to fitting a linear model in R.^[See [*Tidy Modeling with R*](https://www.tmwr.org/base-r.html) for an overview of how these approaches vary.] Here, we introduce `tidymodels` and demonstrate how to construct a basic linear regression model.

[`tidymodels`](https://www.tidymodels.org/) is a collection of packages for statistical modeling and machine learning using `tidyverse` principles. Given this emphasis, it pairs nicely with the tidy-centric approach we have covered so far for tasks such as data visualization, data wrangling, importation of data files, and publishing results.

`tidymodels` is still under active development and contains a range of packages and functions for many different aspects of statistical modeling. Here we demonstrate how to start with data for modeling, specify and train models using different engines using the [`parsnip` package](https://tidymodels.github.io/parsnip/), and understand why these functions are designed this way.

## `scorecard`

As in past exercises, let's use the `rcfss::scorecard` dataset which contains detailed information on all four-year colleges and universities in the United States. Here we will consider the average faculty salary to understand how it is influenced by factors such as the average annual total cost of attendance and whether the university is public, private nonprofit, or private for-profit.

```{r data}
scorecard
glimpse(scorecard)
```

As a first step in modeling, it's always a good idea to plot the data: 

```{r scorecard-plot}
ggplot(data = scorecard,
       mapping = aes(x = cost, 
           y = avgfacsal, 
           col = type)) + 
  geom_point(alpha = .3) + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_viridis_d(option = "plasma", end = .7)
```

We can see that public and private non-profit schools have the strongest correlation between total cost of attendance and average faculty salaries -- private for-profit schools tend to be pretty flat in terms of average salaries regardless of cost of attendance. 

## Build and fit a model {#build-model}

A standard two-way analysis of variance ([ANOVA](https://www.itl.nist.gov/div898/handbook/prc/section4/prc43.htm)) model makes sense for this dataset because we have both a continuous predictor and a categorical predictor. Since the slopes appear to be different for at least two of the college types, let's build a model that allows for two-way interactions. Specifying an R formula with our variables in this way: 

```{r two-way-int, eval = FALSE}
avgfacsal ~ cost * type
```

allows our regression model depending on cost to have separate slopes and intercepts for each type of college. 

For this kind of model, ordinary least squares is a good initial approach. With `tidymodels`, we start by specifying the _functional form_ of the model that we want using the [`parsnip` package](https://tidymodels.github.io/parsnip/). Since there is a numeric outcome and the model should be linear with slopes and intercepts, the model type is ["linear regression"](https://tidymodels.github.io/parsnip/reference/linear_reg.html). We can declare this with: 


```{r lm-tm}
linear_reg()
```

That is pretty underwhelming since, on its own, it doesn't really do much. However, now that the type of model has been specified, a method for _fitting_ or training the model can be stated using the **engine**. The engine value is often a mash-up of the software that can be used to fit or train the model as well as the estimation method. For example, to use ordinary least squares, we can set the engine to be `lm`:

```{r lm-spec}
linear_reg() %>% 
  set_engine("lm")
```

The [documentation page for `linear_reg()`](https://tidymodels.github.io/parsnip/reference/linear_reg.html) lists the possible engines. We'll save this model object as `lm_mod`.

![Artwork by @allison_horst](/img/allison_horst_art/parsnip.png)

```{r lm-mod}
lm_mod <- linear_reg() %>% 
  set_engine("lm")
```

From here, the model can be estimated or trained using the [`fit()`](https://tidymodels.github.io/parsnip/reference/fit.html) function:

```{r lm-fit, dependson = "lm-mod"}
lm_fit <- lm_mod %>% 
  fit(avgfacsal ~ cost * type, data = scorecard)
lm_fit
```

Perhaps our analysis requires a description of the model parameter estimates and their statistical properties. Although the `summary()` function for `lm` objects can provide that, it gives the results back in an unwieldy format. Many models have a `tidy()` method that provides the summary results in a more predictable and useful format (e.g. a data frame with standard column names): 

```{r lm-table, dependson = "lm-fit"}
tidy(lm_fit)
```

## Use a model to predict {#predict-model}

This fitted object `lm_fit` has the `lm` model output built-in, which you can access with `lm_fit$fit`, but there are some benefits to using the fitted parsnip model object when it comes to predicting.

Suppose that, for a publication, it would be particularly interesting to make a plot of the expected average faculty salary for colleges with a total cost of attendance of $20,000. To create such a graph, we start with some new example data that we will make predictions for, to show in our graph:

```{r new-points}
new_points <- expand.grid(
  cost = 20000, 
  type = c("Public", "Private, nonprofit", "Private, for-profit")
)
new_points
```

To get our predicted results, we can use the `predict()` function to find the expected salaries at $20,000 cost of attendance. 

It is also important to communicate the variability, so we also need to find the predicted confidence intervals. If we had used `lm()` to fit the model directly, a few minutes of reading the [documentation page](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html) for `predict.lm()` would explain how to do this. However, if we decide to use a different model to estimate average faculty salaries (_spoiler:_ we will!), it is likely that a completely different syntax would be required. 

Instead, with `tidymodels`, the types of predicted values are standardized so that we can use the same syntax to get these values. 

First, let's generate the expected salary values: 

```{r lm-pred-mean, dependson = c("lm-fit", "new-points")}
mean_pred <- predict(lm_fit, new_data = new_points)
mean_pred
```

When making predictions, the `tidymodels` convention is to always produce a tibble of results with standardized column names. This makes it easy to combine the original data and the predictions in a usable format: 

```{r lm-all-pred, dependson = "lm-pred-mean"}
conf_int_pred <- predict(lm_fit,
  new_data = new_points,
  type = "conf_int"
)
conf_int_pred

# Now combine
plot_data <- new_points %>%
  bind_cols(mean_pred) %>%
  bind_cols(conf_int_pred)

# And plot
ggplot(data = plot_data, mapping = aes(x = type)) +
  geom_point(mapping = aes(y = .pred)) +
  geom_errorbar(
    mapping = aes(
      ymin = .pred_lower,
      ymax = .pred_upper
    ),
    width = .2
  ) +
  labs(y = "Expected average faculty salary")
```

## Model with a different engine {#new-engine}

Every one on your team is happy with that plot _except_ that one person who just read their first book on [Bayesian analysis](https://bayesian.org/what-is-bayesian-analysis/). They are interested in knowing if the results would be different if the model were estimated using a Bayesian approach. In such an analysis, a [_prior distribution_](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7) needs to be declared for each model parameter that represents the possible values of the parameters (before being exposed to the observed data). After some discussion, the group agrees that the priors should be bell-shaped but, since no one has any idea what the range of values should be, to take a conservative approach and make the priors _wide_ using a Cauchy distribution (which is the same as a t-distribution with a single degree of freedom).

The [documentation](https://mc-stan.org/rstanarm/articles/priors.html) on the `rstanarm` package shows us that the `stan_glm()` function can be used to estimate this model, and that the function arguments that need to be specified are called `prior` and `prior_intercept`. It turns out that `linear_reg()` has a [`stan` engine](https://tidymodels.github.io/parsnip/reference/linear_reg.html#details). Since these prior distribution arguments are specific to the Stan software, they are passed as arguments to [`parsnip::set_engine()`](https://tidymodels.github.io/parsnip/reference/set_engine.html). After that, the same exact `fit()` call is used:

```{r go-stan, message = FALSE, warning = FALSE}
# set the prior distribution
prior_dist <- rstanarm::student_t(df = 1)

set.seed(123)

# make the parsnip model
bayes_mod <- linear_reg() %>% 
  set_engine("stan", 
             prior_intercept = prior_dist, 
             prior = prior_dist,
             # increase number of iterations to converge to stable solution
             iter = 4000) 

# train the model
bayes_fit <- bayes_mod %>% 
  fit(avgfacsal ~ cost * type, data = scorecard)

print(bayes_fit, digits = 5)
```

{{% callout note %}}

This kind of Bayesian analysis (like many models) involves randomly generated numbers in its fitting procedure. We can use `set.seed()` to ensure that the same (pseudo-)random numbers are generated each time we run this code. The number `123` isn't special or related to our data; it is just a "seed" used to choose random numbers.

{{% /callout %}}

To update the parameter table, the `tidy()` method is once again used: 

```{r tidy-stan, dependson = "go-stan"}
tidy(bayes_fit, conf.int = TRUE)
```

A goal of the `tidymodels` packages is that the **interfaces to common tasks are standardized** (as seen in the `tidy()` results above). The same is true for getting predictions; we can use the same code even though the underlying packages use very different syntax:

```{r stan-pred, dependson = "go-stan", warning = FALSE, message = FALSE}
bayes_plot_data <- new_points %>% 
  bind_cols(predict(bayes_fit, new_data = new_points)) %>% 
  bind_cols(predict(bayes_fit, new_data = new_points, type = "conf_int"))

ggplot(data = bayes_plot_data, mapping = aes(x = type)) +
  geom_point(mapping = aes(y = .pred)) +
  geom_errorbar(
    mapping = aes(
      ymin = .pred_lower,
      ymax = .pred_upper
    ),
    width = .2
  ) +
  labs(y = "Expected average faculty salary")
```

This isn't very different from the non-Bayesian results (except in interpretation). 

{{% callout note %}}

The [`parsnip`](https://parsnip.tidymodels.org/) package can work with many model types, engines, and arguments. Check out [tidymodels.org/find/parsnip/](https://www.tidymodels.org/find/parsnip/) to see what is available.

{{% /callout %}}

## Why does it work that way? {#why}

The extra step of defining the model using a function like `linear_reg()` might seem superfluous since a call to `lm()` is much more succinct. However, the problem with standard modeling functions is that they don't separate what you want to do from the execution. For example, the process of executing a formula has to happen repeatedly across model calls even when the formula does not change; we can't recycle those computations. 

Also, using the `tidymodels` framework, we can do some interesting things by incrementally creating a model (instead of using single function call). [Model tuning](https://www.tidymodels.org/start/tuning/) with `tidymodels` uses the specification of the model to declare what parts of the model should be tuned. That would be very difficult to do if `linear_reg()` immediately fit the model. 

## Acknowledgments

* Example drawn from [Get Started - Build a model](https://www.tidymodels.org/start/models/) and licensed under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/).
* Artwork by [@allison_horst](https://github.com/allisonhorst/stats-illustrations)

## Session Info

```{r child = here::here("R", "_session-info.Rmd")}
```
