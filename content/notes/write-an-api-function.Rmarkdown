---
title: "Writing API queries"
date: 2019-03-01

type: docs
toc: true
draft: false
aliases: ["/webdata003_api_by_hand.html"]
categories: ["webdata"]

menu:
  notes:
    parent: Getting data from the web
    weight: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r packages, cache = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(stringr)
library(curl)
library(jsonlite)
library(XML)
library(httr)

theme_set(theme_minimal())
```

What happens if someone has not already written a package for the API from which we want to obtain data? We have to write our own function! Fortunately you know how to [write functions](/notes/functions/) - now we need to use them to query an API to obtain data.

First we're going to examine the structure of API requests via the [Open Movie Database](http://www.omdbapi.com/). OMDb is very similar to IMDB, except it has a nice, simple API. We can go to the website, input some search parameters, and obtain both the XML query and the response from it. 

## Determining the shape of an API request

You can play around with the parameters on the OMDB website, and look at the resulting API call and the query you get back:

![](/img/ombd.png)

Let's experiment with different values of the `title` and `year` fields. Notice the pattern in the request. For example for Title = Sharknado and Year = 2013, we get:

``` http
http://www.omdbapi.com/?apikey=[apikey]&t=Sharknado&y=2013&plot=short&r=xml
```

Try pasting this link into the browser. Also experiment with `json` and `xml`.

> The OMDB API used to be free, however in the past year shifted to a private API key due to overwhelming traffic. See in class for a demo API key you can use.

How can we create this request in R?

```{r omdb-key}
# retrieve API key from .RProfile
omdb_key <- getOption("omdb_key")

# create url
request <- str_c("http://www.omdbapi.com/?apikey=", omdb_key, "&", "t=", "Sharknado", "&", "y=", "2013", "&", "plot=", "short", "&", "r=", "xml")
request
```

It works, but it's a bit ungainly. Lets try to abstract that into a function:

```{r omdb-function, dependson = "omdb-key"}
omdb <- function(Key, Title, Year, Plot, Format){
  baseurl <- "http://www.omdbapi.com/?"
  params <- c("apikey=", "t=", "y=", "plot=", "r=")
  values <- c(Key, Title, Year, Plot, Format)
  param_values <- map2_chr(params, values, str_c)
  args <- str_c(param_values, collapse = "&")
  str_c(baseurl, args)
}

omdb(omdb_key, "Sharknado", "2013", "short", "xml")
```

Now we have a handy function that returns the API query. We can paste in the link, but we can also obtain data from within R:

```{r omdb-xml, dependson = "omdb-key"}
request_sharknado <- omdb(omdb_key, "Sharknado", "2013", "short", "xml")
con <- curl(request_sharknado)
answer_xml <- readLines(con)
close(con)
answer_xml
```

```{r omdb-json, dependson = "omdb-key", warning = FALSE}
request_sharknado <- omdb(omdb_key, "Sharknado", "2013", "short", "json")
con <- curl(request_sharknado)
answer_json <- readLines(con)
close(con)
answer_json %>% 
  prettify()
```

We have a form of data that is obviously structured. What is it?

## Intro to JSON and XML

These are the two common languages of web services: **J**ava**S**cript **O**bject **N**otation and e**X**tensible **M**arkup **L**anguage. 

Here's an example of JSON: from [this wonderful site](https://zapier.com/learn/apis/chapter-3-data-formats/)

```javascript
{
  "crust": "original",
  "toppings": ["cheese", "pepperoni", "garlic"],
  "status": "cooking",
  "customer": {
    "name": "Brian",
    "phone": "573-111-1111"
  }
}
```

And here is XML:

```XML
<order>
    <crust>original</crust>
    <toppings>
        <topping>cheese</topping>
        <topping>pepperoni</topping>
        <topping>garlic</topping>
    </toppings>
    <status>cooking</status>
</order>
```

You can see that both of these data structures are quite easy to read. They are "self-describing". In other words, they tell you how they are meant to be read.

There are easy means of taking these data types and creating R objects. Our JSON response above can be parsed using `jsonlite::fromJSON()`:

```{r parse-json, dependson = "omdb-json"}
answer_json %>% 
  fromJSON()
```

The output is a named list! A familiar and friendly R structure. Because data frames are lists, and because this list has no nested lists-within-lists,^[Because I strip it out. We'll see shortly how to handle nested lists-within-lists.] we can coerce it very simply:

```{r json-df, dependson = "omdb-json"}
answer_json %>% 
  fromJSON() %>% 
  # remove ratings element for now
  list_modify(Ratings = NULL) %>%
  as_tibble()
```

A similar process exists for XML formats:

```{r xml-parse, dependson = "omdb-xml"}
ans_xml_parsed <- xmlParse(answer_xml)
ans_xml_parsed
```

Not exactly the response we were hoping for! This shows us some of the XML document's structure: 

  * a `<root>` node with a single child, `<movie>`. 
  * the information we want is all stored as attributes

From [Nolan and Lang 2014](http://link.springer.com.proxy.uchicago.edu/book/10.1007%2F978-1-4614-7900-0):

> The `xmlRoot()` function returns an object of class `XMLInternalElementNode`. This is a regular
XML node and not specific to the root node, i.e., all XML nodes will appear in R with this class
or a more specific class. An object of class XMLInternalElementNode has four fields: name,
attributes, children and value, which we access with the methods xmlName(), xmlAttrs(), xmlChildren(), and xmlValue()

| field | method |
|:-----:|:------:|
| name  | `xmlName()` |
| attributes | `xmlAttrs()` |
| children  | `xmlChildren()` |
| value    | `xmlValue()`


```{r xml-root-attrs, dependson = "xml-parse"}
ans_xml_parsed_root <- xmlRoot(ans_xml_parsed)[["movie"]]  # could also use [[1]]
ans_xml_parsed_root
ans_xml_attrs <- xmlAttrs(ans_xml_parsed_root)
ans_xml_attrs
```

```{r xml-df, dependson = "xml-root-attrs"}
ans_xml_attrs %>%
  t() %>%
  as_tibble()
```

## Introducing the easy way: `httr`

`httr` is yet another star in the tidyverse, this one designed to facilitate all things HTTP from within R. This includes the major HTTP verbs, which are:^[[Source: HTTP made really easy](http://www.jmarshall.com/easy/http/)]

* **GET**: fetch an existing resource. The URL contains all the necessary information the server needs to locate and return the resource.
* **POST**: create a new resource. POST requests usually carry a payload that specifies the data for the new resource.
* **PUT**: update an existing resource. The payload may contain the updated data for the resource.
* **DELETE**: delete an existing resource.

HTTP is the foundation for APIs; understanding how it works is the key to interacting with all the diverse APIs out there. An excellent beginning resource for APIs (including HTTP basics) is [this simple guide](https://zapier.com/learn/apis/).

`httr` contains one function for every HTTP verb. The functions have the same names as the verbs (e.g. `GET()`, `POST()`). They have more informative outputs than simply using `curl`, and come with some nice convenience functions for working with the output:

```{r httr-json}
sharknado_json <- omdb(omdb_key, "Sharknado", "2013", "short", "json")
response_json <- GET(sharknado_json)
content(response_json, as = "parsed", type = "application/json")
```

```{r httr-xml}
sharknado_xml <- omdb(omdb_key, "Sharknado", "2013", "short", "xml")
response_xml <- GET(sharknado_xml)
content(response_xml, as = "parsed")
```

In addition, `httr` gives us access to lots of useful information about the quality of our response. For example, the header:

```{r httr-headers, dependson = "httr-xml"}
headers(response_xml)
```

And also a handy means to extract specifically the HTTP status code:

```{r httr-status, dependson = "httr-xml"}
status_code(response_xml)
```

Code^[[HTTP Status Codes](http://www.restapitutorial.com/httpstatuscodes.html)] | Status
-------|--------|
1xx    | Informational
2xx    | Success
3xx    | Redirection
4xx    | Client error (you did something wrong)
5xx    | Server error (server did something wrong)

> [(Perhaps a more intuitive, cat-based explanation of error codes)](https://www.flickr.com/photos/girliemac/sets/72157628409467125).

In fact, we didn't need to create `omdb()` at all! `httr` provides a straightforward means of making an http request:

```{r httr-get-only}
sharknado_2 <- GET("http://www.omdbapi.com/?",
                   query = list(t = "Sharknado 2: The Second One",
                                y = 2014,
                                plot = "short",
                                r = "json",
                                apikey = omdb_key))

content(sharknado_2)
```

We get the same answer as before! With `httr`, we are able to pass in the named arguments to the API call as a named list. We are also able to use spaces in movie names - `httr` encodes these in the URL before making the GET request.

The documentation for `httr` includes two useful vignettes:

* [`httr` quickstart guide](https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html) - summarizes all the basic `httr` functions like above
* [Best practices for writing an API package](https://cran.r-project.org/web/packages/httr/vignettes/api-packages.html) - document outlining the key issues involved in writing API wrappers in R

## Applying `httr` to the Microsoft Emotion API

> This historic example is preserved as a demonstration of using `httr` to interact with deep learning models. Unfortunately Microsoft terminated this API and is no longer publicly usable. `r emo::ji("sad")`

APIs can be used in conjunction with cloud computing and deep learning platforms that cannot be deployed on a local machine. Consider the [Microsoft Emotion API](https://azure.microsoft.com/en-us/services/cognitive-services/emotion/):

> The Emotion API takes a facial expression in an image as an input, and returns the confidence across a set of emotions for each face in the image, as well as bounding box for the face, using the Face API. If a user has already called the Face API, they can submit the face rectangle as an optional input.
    The emotions detected are anger, contempt, disgust, fear, happiness, neutral, sadness, and surprise. These emotions are understood to be cross-culturally and universally communicated with particular facial expressions.

Here is how we can use R and the `httr` package to send a request to the Microsoft Emotion API to analyze a video and retrieve the results.^[Based on [Analyzing Emotions using Facial Expressions in Video with Microsoft AI and R](https://blog.exploratory.io/analyzing-emotions-using-facial-expressions-in-video-with-microsoft-ai-and-r-8f7585dd0780), which is itself based on the original post [How to apply face recognition API technology to data journalism with R and python](https://benheubl.github.io/data%20analysis/fr/), which served as the basis for [The many debate faces of Donald Trump and Hillary Clinton](http://www.economist.com/blogs/graphicdetail/2016/10/daily-chart-12).] As our sample video, we'll use [a sample five minute video clip](https://www.dropbox.com/s/zfmaswf8s9c58om/blog2.mp4?dl=1%27) from the third 2016 U.S. presidential debate between Donald J. Trump and Hillary Clinton.

```{r emotion-api, eval = FALSE}
# Set an endpoint for Emotion in Video API with "perFrame" output
apiUrl <- "https://api.projectoxford.ai/emotion/v1.0/recognizeInVideo?outputStyle=perFrame"

# Set URL for accessing the video
urlVideo <- "https://www.dropbox.com/s/zfmaswf8s9c58om/blog2.mp4?dl=1"

# Request Microsoft AI start processing the video via POST
faceEMO <- httr::POST(
  url = apiUrl,
  content_type("application/json"),
  add_headers(.headers = c("Ocp-Apim-Subscription-Key" = getOption("emotion_api"))),
  body = list(url = urlVideo),
  encode = "json"
)

# url to access the operation
operationLocation <- headers(faceEMO)[["operation-location"]]

# it can take awhile to process a long video
# use a while loop to wait for the processing to finish
# and retrieve the results
while(TRUE){
  # retrieve results and extract content
  ret <- GET(operationLocation,
             add_headers(.headers = c("Ocp-Apim-Subscription-Key" = getOption("emotion_api"))))
  
  con <- content(ret)
  
  # if the process is still running, print the progress and continue waiting
  if(is.null(con$status)){
    warning("Connection Error, retry after 1 minute")
    Sys.sleep(60)
  } else if (con$status == "Running" | con$status == "Uploading"){
    cat(paste0("status ", con$status, "\n"))
    cat(paste0("progress ", con$progress, "\n"))
    Sys.sleep(60)
  } else {
    # once the process is done, exit the loop
    cat(paste0("status ", con$status, "\n"))
    break()
  }
}

# extract data from the results
data <- (con$processingResult %>%
           fromJSON())$fragments

# data$events is list of events that has a data.frame column,
# so it has to be flattened using a series of map functions
data$events <- map(data$events, ~ .x %>%
    map(flatten) %>%
    bind_rows()
)

# print results
data

# clean up and save
emotion <- data %>%
  as_tibble %>%
  # unnest the list of data frames
  unnest(events) %>%
  # remove the moderator
  filter(id != 2) %>%
  # create a row id variable, use same row id for each set of speakers
  mutate(row_id = ceiling(row_number() / 2)) %>%
  # convert from wide to long, one row for each id-emotion
  gather(key, value, starts_with("scores")) %>%
  mutate(key = str_replace(key, "scores.", ""),
         id = recode(id, `0` = "Trump",
                     `1` = "Clinton")) %>%
  # remove neutral expressions and write to disk
  filter(key != "neutral") %>%
  write_rds("data/debate_emotion.rds")
```

This script requires you to [create your own API key](https://azure.microsoft.com/en-us/try/cognitive-services/my-apis/) for the Microsoft Emotion API and would take about an hour to process the video and retrieve the results. Instead, you can just use the prepped data frame stored in the `rcfss` package.

```{r get-emotion-data}
# already ran the API and stored the data frame in the rcfss package
data("emotion", package = "rcfss")
emotion
```

> See `?emotion` for more documentation on the variables.

What could we do with this information? A simple analysis would be to visualize the emotions of each candidate over time:

```{r emotion-viz}
ggplot(emotion, aes(row_id, value, color = key)) +
  facet_wrap(~ id, nrow = 2) +
  geom_smooth(se = FALSE) +
  scale_color_brewer(type = "qual") +
  labs(title = "Candidate emotions during final 2016 U.S. presidential debate",
       subtitle = "Five-minute sample",
       x = "Frame",
       y = "Probability of emotion",
       color = "Emotion")
```

Hillary Clinton's facial expressions are marked predominantly by happiness, whereas Donald Trump's facial expressions are mostly sad.^[Not exactly predictive of the election results.]

## Acknowledgments

```{r child = here::here("R", "_ack_stat545.Rmd")}
```
* Microsoft Emotion API example drawn from [Analyzing Emotions using Facial Expressions in Video with Microsoft AI and R](https://blog.exploratory.io/analyzing-emotions-using-facial-expressions-in-video-with-microsoft-ai-and-r-8f7585dd0780)

## Session Info

```{r child = here::here("R", "_session-info.Rmd")}
```
