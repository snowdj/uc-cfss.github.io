---
title: "Practicing tidytext with Hamilton"
date: 2019-03-01

type: docs
toc: true
draft: false
aliases: []
categories: ["text"]

menu:
  notes:
    parent: Text analysis
    weight: 3
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r packages, cache = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidytext)
library(ggtext)
library(here)

set.seed(123)
theme_set(theme_minimal())
```

About seven months ago, my wife and I became addicted to Hamilton.

![My name is Alexander Hamilton](https://media.giphy.com/media/d4bmtcUmgA8ylgCk/giphy.gif)

I admit, we were quite late to the party. I promise we did like it, but I wanted to wait and see the musical in-person before listening to the soundtrack. Alas, having three small children limits your free time to go out to the theater for an entire evening. So I finally caved and started listening to the soundtrack on Spotify. And it's amazing! My son's favorite song (he's four BTW) is My Shot.

![My Shot](https://media.giphy.com/media/l378ovNpNyKXCQCHu/giphy.gif)

One of the nice things about the musical is that it is [sung-through](https://en.wikipedia.org/wiki/Sung-through), so the lyrics contain essentially all of the dialogue. This provides an interesting opportunity to use the `tidytext` package to analyze the lyrics. Here, I use the `geniusr` package to obtain the complete lyrics from [Genius](https://genius.com/albums/Lin-manuel-miranda/Hamilton-an-american-musical-original-broadway-cast-recording).[^lyrics]

```{r get-hamilton, eval = FALSE, include = FALSE}
library(geniusr)

# Genius album ID number
hamilton_id <- 131575

# retrieve track list
hamilton_tracks <- get_album_tracklist_id(album_id = hamilton_id)

# retrieve song lyrics
hamilton_lyrics <- hamilton_tracks %>%
  mutate(lyrics = map(.x = song_lyrics_url, get_lyrics_url))

# unnest and clean-up
hamilton <- hamilton_lyrics %>%
  unnest(cols = lyrics, names_repair = "universal") %>%
  select(song_number, line, section_name, song_name) %>%
  group_by(song_number) %>%
  # add line number
  mutate(line_num = row_number()) %>%
  # reorder columns and convert speaker to title case
  select(song_number, song_name, line_num, line, speaker = section_name) %>%
  mutate(speaker = str_to_title(speaker),
         line = str_replace_all(line, "â€™", "'")) %>%
  # write to disk
  write_csv(path = here("static", "data", "hamilton.csv"))
glimpse(hamilton)
```

```{r hamilton}
hamilton <- read_csv(file = here("static", "data", "hamilton.csv")) %>%
  mutate(song_name = parse_factor(song_name))
glimpse(hamilton)
```

Along with the lyrics, we also know the singer (`speaker`) of each line of dialogue. This will be helpful if we want to perform analysis on a subset of singers.

## Convert to tidytext format

Currently, `hamilton` is stored as one-row-per-line of lyrics. The definition of a single "line" is somewhat arbitrary. For substantial analysis, we will convert the corpus to a tidy-text data frame of one-row-per-token. Initially, we will use `unnest_tokens()` to tokenize all unigrams.

```{r tidy, dependson = "hamilton"}
hamilton_tidy <- hamilton %>%
  unnest_tokens(output = word, input = line)
hamilton_tidy
```

Remember that by default, `unnest_tokens()` automatically converts all text to lowercase and strips out punctuation.

## Length of songs by words

An initial check reveals the length of each song in terms of the number of words in its lyrics.^[Though lyrics' length is not always [a good measure of a musical's pacing](https://fivethirtyeight.com/features/hamilton-is-the-very-model-of-a-modern-fast-paced-musical/).]

```{r song-length, dependson = "hamilton", fig.asp = 1.1}
ggplot(data = hamilton_tidy, mapping = aes(x = fct_rev(song_name))) +
  geom_bar() +
  coord_flip() +
  labs(
    title = "Length of songs in Hamilton",
    x = NULL,
    y = "Song length (in words)",
    caption = "Source: Genius API"
  )
```

As a function of number of words, Non-Stop is the longest song in the musical.

## Stop words

Of course not all words are equally important. Consider the 10 most frequent words in the lyrics:

```{r stopwords, dependson = "tidy"}
hamilton_tidy %>%
  count(word) %>%
  arrange(desc(n))
```

Not particularly informative. We can identify a list of stopwords using `get_stopwords()` then remove them via `anti_join()`.^[I told you filtering joins would be useful one day, but you didn't believe me!]

```{r stop-remove, dependson = "tidy"}
# remove stop words
hamilton_tidy <- hamilton_tidy %>%
  anti_join(get_stopwords(source = "smart"))

hamilton_tidy %>%
  count(word) %>%
  slice_max(n = 20, order_by = n) %>%
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col() +
  coord_flip() + 
  theme_minimal() +
  labs(
    title = "Frequency of Hamilton lyrics",
    x = NULL,
    y = NULL
  )
```

Now the words seem more relevant to the specific story being told in the musical.

## Words used most by each cast member

Since we know which singer performs each line, we can examine the relative significance of different words to different characters. [**Term frequency-inverse document frequency** (tf-idf)](https://www.tidytextmining.com/tfidf.html) is a simple metric for measuring the importance of specific words to a corpus. Here let's calculate the top ten words for each member of the principal cast.

```{r tf-idf, dependson = "stop-remove", fig.asp = 1.1}
# principal cast via Wikipedia
principal_cast <- c("Hamilton", "Eliza", "Burr", "Angelica", "Washington",
                    "Lafayette", "Jefferson", "Mulligan", "Madison",
                    "Laurens", "Philip", "Peggy", "Maria", "King George")

# calculate tf-idf scores for words sung by the principal cast
hamilton_tf_idf <- hamilton_tidy %>%
  filter(speaker %in% principal_cast) %>%
  mutate(speaker = parse_factor(x = speaker, levels = principal_cast)) %>%
  count(speaker, word) %>%
  bind_tf_idf(term = word, document = speaker, n = n)

# visualize the top N terms per character by tf-idf score
hamilton_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(speaker) %>%
  slice_max(n = 10, order_by = tf_idf, with_ties = FALSE) %>%
  # resolve ambiguities when same word appears for different characters
  ungroup() %>%
  mutate(word = reorder_within(x = word, by = tf_idf, within = speaker)) %>%
  ggplot(mapping = aes(x = word, y = tf_idf)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered() +
  labs(
    title = "Most important words in *Hamilton*",
    subtitle = "Principal cast only",
    x = NULL,
    y = "tf-idf",
    caption = "Source: Genius API"
  ) +
  facet_wrap(~speaker, scales = "free") +
  coord_flip() +
  theme(plot.title = element_markdown())
```

Again, some expected results stick out. Hamilton is always singing about not throwing away his shot, Eliza is helplessly in love with Alexander, while Burr regrets not being "in the room where it happens". And don't forget King George's love songs to his wayward children.

![Jonathan Groff](https://media.giphy.com/media/26u6duhyJTMmLGMAE/giphy.gif)

## Sentiment analysis

**Sentiment analysis** utilizes the text of the lyrics to classify content as positive or negative. Dictionary-based methods use pre-generated lexicons of words independently coded as positive/negative. We can combine one of these dictionaries with the Hamilton tidy-text data frame using `inner_join()` to identify words with sentimental affect, and further analyze trends.

Here we use the `afinn` dictionary which classifies `r nrow(get_sentiments(lexicon = "afinn")) %>% scales::comma()` words on a scale of $[-5, +5]$.

```{r sentiment, dependson = "stop-remove", fig.asp = 1.0}
# afinn dictionary
get_sentiments(lexicon = "afinn")

hamilton_afinn <- hamilton_tidy %>%
  # join with sentiment dictionary
  inner_join(get_sentiments(lexicon = "afinn")) %>%
  # create row id and cumulative sentiment over the entire corpus
  mutate(cum_sent = cumsum(value),
         id = row_number())
hamilton_afinn
```

First, we can examine the sentiment of each song individually by calculating the average sentiment of each word in the song.

```{r sentiment-song, dependson = "sentiment", fig.asp = 1.0}
# sentiment by song
hamilton_afinn %>%
  group_by(song_name) %>%
  summarize(sent = mean(value)) %>%
  ggplot(mapping = aes(x = fct_rev(song_name), y = sent, fill = sent)) +
  geom_col() +
  scale_fill_viridis_c() +
  coord_flip() +
  labs(
    title = "Positive/negative sentiment in *Hamilton*",
    subtitle = "By song",
    x = NULL,
    y = "Average sentiment",
    fill = "Average\nsentiment",
    caption = "Source: Genius API"
  ) +
  theme(plot.title = element_markdown(),
        legend.position = "none")
```

Again, the general themes of the songs come across in this analysis. "Alexander Hamilton" introduces Hamilton's tragic backstory and difficult circumstances before emigrating to New York. "Dear Theodosia" is a love letter from Burr and Hamilton, promising to make the world a better place for their respective children.

However, this also illustrates some problems with dictionary-based sentiment analysis. Consider the back-to-back songs "Helpless" and "Satisfied". "Helpless" depicts Eliza and Alexander falling in love with one another and getting married, while "Satisfied" recounts these same events from the perspective of Eliza's sister Angelica who suppresses her own feelings for Hamilton out of a sense of duty to her sister. From the perspective of the listener, "Helpless" is the far more positive song of the pair. Why are they reversed based on the textual analysis?

```{r sentiment-outliers, dependson = "sentiment"}
get_sentiments(lexicon = "afinn") %>%
  filter(word %in% c("helpless", "satisfied"))
```

Herein lies the problem with dictionary-based methods. The AFINN lexicon codes "helpless" as a negative term and "satisfied" as a positive term. On their own this makes sense, but in the context of the music clearly Eliza is "helplessly" in love while Angelica will in fact never be "satisfied" because she cannot be with Alexander. A dictionary-based sentiment classification will always miss these nuances in language.

We could also examine the general disposition of each speaker based on the sentiment of their lyrics. Consider the principal cast below:

```{r sentiment-by-speaker, dependson = "sentiment"}
hamilton_afinn %>%
  filter(speaker %in% principal_cast) %>%
  # calculate average sentiment by character with standard error
  group_by(speaker) %>%
  summarize(sent = mean(value),
            se = sd(value) / n()) %>%
  # generate plot sorted from positive to negative
  ggplot(mapping = aes(x = fct_reorder(speaker, sent), y = sent, fill = sent)) +
  geom_pointrange(mapping = aes(
    ymin = sent - 2 * se,
    ymax = sent + 2 * se
  )) +
  coord_flip() +
  labs(
    title = "Positive/negative sentiment in *Hamilton*",
    subtitle = "By speaker",
    x = NULL,
    y = "Average sentiment",
    caption = "Source: Genius API"
  ) +
  theme(plot.title = element_markdown(),
        legend.position = "none")
```

Given his generally neutral sentiment, Aaron Burr clearly follows his own guidance.

![Talk less](https://media.giphy.com/media/vDZw32VEqrGOQ/giphy.gif)

![Smile more](https://media.giphy.com/media/GPLL2dSTt9Jvy/giphy.gif)

Also, can we please note Peggy's general pessimism?

![And Peggy!](https://media.giphy.com/media/20EwQf08wjYrbq9Pfn/giphy.gif)

Tracking the cumulative sentiment across the entire musical, it's easy to identify the high and low points.

```{r sentiment-cum, dependson = "sentiment", fig.asp = 1.6}
ggplot(data = hamilton_afinn, mapping = aes(x = id, y = cum_sent)) +
  geom_line() +
  # label the start of each song
  scale_x_reverse(breaks = hamilton_afinn %>%
                             group_by(song_number) %>%
                             filter(id == min(id)) %>%
                       pull(id),
                     labels = hamilton_afinn %>%
                             group_by(song_number) %>%
                             filter(id == min(id)) %>%
                       pull(song_name)) +
  labs(
    title = "Positive/negative sentiment in *Hamilton*",
    x = NULL,
    y = "Cumulative sentiment",
    caption = "Source: Genius API"
  ) +
  # transpose to be able to fit song titles on the graph
  coord_flip() +
  theme(panel.grid.minor.y = element_blank(),
        plot.title = element_markdown())
```

After the initial drop from "Alexander Hamilton", the next peaks in the graph show several positive events in Hamilton's life: meeting his friends, becoming Washington's secretary, and meeting and marrying Eliza. The musical experiences a drop in tone during the rough years of the revolution and Hamilton's dismissal back to New York, then rebounds as the revolutionaries close in on victory at Yorktown. Hamilton's challenges as a member of Washington's cabinet and rivalry with Jefferson are captured in the up-and-down swings in the graph, rises up with "One Last Time" and Hamilton writing Washington's Farewell Address, dropping once again with "Hurricane" and the revelation of Hamilton's affair, rising as Alexander and Eliza reconcile before finally descending once more upon Hamilton's death in his duel with Burr.

## Pairs of words

```{r}
library(widyr)
library(ggraph)

# calculate all pairs of words in the musical
hamilton_pair <- hamilton %>%
  unnest_tokens(output = word, input = line, token = "ngrams", n = 2) %>%
  separate(col = word, into = c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% get_stopwords(source = "smart")$word,
         !word2 %in% get_stopwords(source = "smart")$word) %>%
  drop_na(word1, word2) %>%
  count(word1, word2, sort = TRUE)

# filter for only relatively common combinations
bigram_graph <- hamilton_pair %>%
  filter(n > 3) %>%
  igraph::graph_from_data_frame()

# draw a network graph
set.seed(1776) # New York City
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), show.legend = FALSE, alpha = .5) +
  geom_node_point(color = "#0052A5", size = 3, alpha = .5) +
  geom_node_text(aes(label = name), vjust = 1.5) +
  ggtitle("Word Network in Lin-Manuel Miranda's *Hamilton*") +
  theme_void() +
  theme(plot.title = element_markdown())
```

Finally we can examine the colocation of pairs of words to look for common usage. It's apparent there are several major themes detected through this approach, including the Hamilton/Jefferson relationship, "Aaron Burr, sir", Philip's song with his mother (un, deux, trois, quatre, ...), the rising up of the colonies, and those young, scrappy, and hungry men.

```{r spotify, dependson = "tidy", eval = FALSE, include = FALSE}
hamilton_spotify <- spotifyr::get_album_tracks(id = "1kCHru7uhxBUdzkm4gzRQc", limit = 50) %>%
  # fix missing song from spotify info
  mutate(track_number = ifelse(name == "Non-Stop", 24, track_number),
         song_number = ifelse(disc_number == 2,
                              track_number + max(track_number[disc_number == 1]),
                              track_number))
hamilton_audio_features <- spotifyr::get_track_audio_features(ids = hamilton_spotify$id)

# join together
hamilton_audio <- hamilton_spotify %>%
  # remove duplicate columns that actually have differing data
  select(-type, -uri, -duration_ms) %>%
  left_join(hamilton_audio_features) %>%
  select(spotify_id = id, duration_ms, explicit, name, song_number, danceability:tempo, time_signature)
```

```{r length-words-duration, dependson = c("tidy", "spotify"), eval = FALSE, include = FALSE}
hamilton_tidy %>%
  count(song_number, song_name) %>%
  left_join(hamilton_audio) %>%
  ggplot(mapping = aes(x = n, y = duration_ms / 1000)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggrepel::geom_text_repel(mapping = aes(label = song_name), alpha = .3, size = 3) +
  scale_y_time() +
  labs(
    x = "Number of words",
    y = "Length of song (duration)",
    caption = "Lyrics: Genius API\nDuration: Spotify API"
  )
```

## Acknowledgments

* This page is derived in part from [A Sentiment Analysis of Hamilton: The broom Where it Happens / When are these #rcatladies gonna rise up?](https://seankross.com/2016/08/30/A-Sentiment-Analysis-of-Hamilton.html) and licensed under a [Creative Commons Attribution 4.0 International (CC BY 4.0) License](https://creativecommons.org/licenses/by/4.0/).
* This page is derived in part from [Alexander Hamilton: The Breakdown](https://rstudio-pubs-static.s3.amazonaws.com/516633_c5ceb17730f7453fb3422884d55b5144.html).
* This page is derived in part from [Tidytext Analysis](https://www2.stat.duke.edu/courses/Spring19/sta199.001/slides/lec-slides/14b-text-analysis.html#1) and licensed under a [Creative Commons Attribution 4.0 International (CC BY 4.0) License](https://creativecommons.org/licenses/by/4.0/).

[^lyrics]: There are a number of ways to obtain the lyrics for the entire soundtrack. [One approach](https://seankross.com/2016/08/30/A-Sentiment-Analysis-of-Hamilton.html) is to use [`rvest` and web scraping](/notes/web-scraping/) to extract the lyrics from sources online. However here I used the Genius API and [`geniusr`](https://ewenme.github.io/geniusr/) to systematically collect the lyrics from an authoritative (and legal) source. The code below was used to obtain the lyrics for all the songs. Note that you need to [authenticate using an API token](https://ewenme.github.io/geniusr/articles/geniusr.html#auth) in order to use this code.

    ```{r get-hamilton, include = TRUE}
    ```
    
## Session Info

```{r child = here::here("R", "_session-info.Rmd")}
```
