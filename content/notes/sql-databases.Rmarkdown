---
title: "Accessing databases using dbplyr"
date: 2019-03-01

type: docs
toc: true
draft: false
aliases: ["/distrib001_database.html"]
categories: ["distributed-computing"]

menu:
  notes:
    parent: Distributed computing
    weight: 1
---

```{r setup2, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

```{r packages, message = FALSE, warning = FALSE, cache = FALSE}
library(tidyverse)
set.seed(1234)

theme_set(theme_minimal())
```

So far we've only worked with data stored locally in-memory as **data frames**. However there are also situations where you want to work with data stored in an external **database**. Databases are generally stored remotely on-disk, as opposed to in memory. If your data is already stored in a database, or if you have too much data to fit it all into memory simultaneously, you need a way to access it. Fortunately for you, `dplyr` offers support for on-disk databases through `dbplyr`.

## SQL

**Structured Query Language** (SQL) is a means of communicating with a relational database management system. There are different types of SQL databases which offer varying functionality:

* [SQLite](https://www.sqlite.org/)
* [MySQL](https://www.mysql.com/)
* [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-2016)
* [PostgreSQL](https://www.postgresql.org/)
* [BigQuery](https://cloud.google.com/bigquery/)

Databases can also be stored across many platforms. Some types of databases (such as SQLite) can be stored as a single file and loaded in-memory like a data frame. However for large or extremely complex databases, a local computer is insufficient. Instead, one uses a distributed computing platform to store their database in the cloud. Examples include the [UChicago Research Computing Center (RCC)](https://rcc.uchicago.edu/), [Amazon Web Services](https://aws.amazon.com/), and [Google Cloud Platform](https://cloud.google.com/). Note that hosting platforms not typically free (though you can request an account with RCC as a student).

## Getting started with SQLite

First you need to install `dbplyr`:

```r
install.packages("dbplyr")
```

Depending on the type of database, you also need to install the appropriate **database interface** (DBI) package. The DBI package provides the necessary interface between the database and `dplyr`. Five commonly used backends are:

* [`RMySQL`](https://github.com/rstats-db/RMySQL#readme) connects to MySQL and MariaDB
* [`RPostgreSQL`](https://CRAN.R-project.org/package=RPostgreSQL) connects to Postgres and Redshift.
* [`RSQLite`](https://github.com/rstats-db/RSQLite) embeds a SQLite database.
* [`odbc`](https://github.com/rstats-db/odbc#odbc) connects to many commercial databases via the open database connectivity protocol.
* [`bigrquery`](https://github.com/rstats-db/bigrquery) connects to Google's BigQuery.

## Connecting to the database

Let's create a local SQLite database using the `flights` data.

```{r db-create, cache = FALSE}
library(dbplyr)
my_db <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
```

The first argument to `DBI::dbConnect()` is the database backend. SQLite only requires one other argument: the path to the database. Here, we use `:memory:` to create a temporary in-memory database.

To add data to the database, use `copy_to()`. Let's stock the database with `nycflights13::flights`:

```{r copy-to}
library(nycflights13)
copy_to(my_db,
        flights,
        temporary = FALSE,
        indexes = list(
          c("year", "month", "day"),
          "carrier",
          "tailnum"
        )
)
```

Now that we copied the data, we can use `tbl()` to reference a specific table inside the database:

```{r tbl}
flights_db <- tbl(my_db, "flights")
flights_db
```

## Basic verbs

```{r verbs}
select(flights_db, year:day, dep_delay, arr_delay)
filter(flights_db, dep_delay > 240)
arrange(flights_db, year, month, day)
mutate(flights_db, speed = air_time / distance)
summarise(flights_db, delay = mean(dep_time))
```

The commands are generally the same as you would use in `dplyr`. The only difference is that `dplyr` converts your R commands into SQL syntax:

```{r verbs-sql, message = TRUE}
select(flights_db, year:day, dep_delay, arr_delay) %>%
  show_query()
```

`dbplyr` is also lazy:

* It never pulls data into R unless you explicitly ask for it
* It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.

```{r lazy}
c1 <- filter(flights_db, year == 2013, month == 1, day == 1)
c2 <- select(c1, year, month, day, carrier, dep_delay, air_time, distance)
c3 <- mutate(c2, speed = distance / air_time * 60)
c4 <- arrange(c3, year, month, day, carrier)
```

Nothing has actually gone to the database yet.

```{r lazy-result}
c4
```

Now we finally communicate with the database, but only retrieved the first 10 rows (notice the `??` in `query [?? x 8]`). This is a built-in feature to avoid downloading an extremely large data frame our machine cannot handle. To obtain the full results, use `collect()`:

```{r collect}
collect(c4)
```

## Google Bigquery

[**Google Bigquery**](https://cloud.google.com/bigquery/) is a distributed cloud platform for data warehousing and analytics. It can scan terabytes of data in seconds and petabytes in minutes. It has flexible pricing that scales depending on your demand on their resources, and could cost as little as pennies, though depending on your computation may cost more.

## Interacting with Google Bigquery via `dplyr`

Google Bigquery hosts several public (and free) datasets. One is the [NYC Taxi and Limousine Trips](https://cloud.google.com/bigquery/public-data/nyc-tlc-trips) dataset, which contains trip records from all trips completed in yellow and green taxis in NYC from 2009 to 2015. Records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. The dataset itself is hundreds of gigabytes and could never be loaded on a desktop machine. But fortunately we can harness the power of the cloud.

To connect to the database, we use the `bigrquery` library and `bigrquery::bigquery()`:

```{r bigrquery}
library(bigrquery)

taxi <- DBI::dbConnect(bigrquery::bigquery(),
                       project = "nyc-tlc",
                       dataset = "yellow",
                       billing = getOption("bigquery_id"))
taxi
```

* `project` - the project that is hosting the data
* `dataset` - the specific database to be accessed
* `billing` - your unique id to access the data (and be charged if you run too many queries or use to much computing power). You need to [create an account](https://cloud.google.com/bigquery/quickstart-web-ui#before-you-begin) in order to use BigQuery, even if you want to access the free datasets. I stored mine in `.Rprofile` using `options()`.^[This may not make sense to you. You will learn more about storing credentials next week in our unit on accessing data from the web.]

First lets determine in 2014, how many trips per taken each month in yellow cabs? The SQL syntax is:

```sql
SELECT
  LEFT(STRING(pickup_datetime), 7) month,
  COUNT(*) trips
FROM
  [nyc-tlc:yellow.trips]
WHERE
  YEAR(pickup_datetime) = 2014
GROUP BY
  1
ORDER BY
  1
```

In `dbplyr`, we use:

```{r trips-by-month, eval = FALSE}
system.time({
  trips_by_month <- taxi %>%
    tbl("trips") %>%
    filter(year(pickup_datetime) == 2014) %>%
    mutate(month = month(pickup_datetime)) %>%
    count(month) %>%
    arrange(month) %>%
    collect()
})
trips_by_month
```

What about the average speed per hour of day in yellow cabs?

```{r speed-per-hour, eval = FALSE}
system.time({
  speed_per_hour <- taxi %>%
    tbl("trips") %>%
    mutate(hour = hour(pickup_datetime),
           trip_duration = (dropoff_datetime - pickup_datetime) /
             3600000000) %>%
    mutate(speed = trip_distance / trip_duration) %>%
    filter(fare_amount / trip_distance >= 2,
           fare_amount / trip_distance <= 10) %>%
    group_by(hour) %>%
    summarize(speed = mean(speed)) %>%
    arrange(hour) %>%
    collect()
})

ggplot(speed_per_hour, aes(hour, speed)) +
  geom_line() +
  labs(title = "Average Speed of NYC Yellow Taxis",
       x = "Hour of day",
       y = "Average speed, in MPH")
```

Finally, what is the average speed by day of the week?

```{r speed-per-day, eval = FALSE}
system.time({
  speed_per_day <- taxi %>%
    tbl("trips") %>%
    mutate(hour = hour(pickup_datetime),
           day = dayofweek(pickup_datetime),
           trip_duration = (dropoff_datetime - pickup_datetime) /
             3600000000) %>%
    mutate(speed = trip_distance / trip_duration) %>%
    filter(fare_amount / trip_distance >= 2,
           fare_amount / trip_distance <= 10,
           hour >= 8,
           hour <= 18) %>%
    group_by(day) %>%
    summarize(speed = mean(speed)) %>%
    arrange(day) %>%
    collect()
})
speed_per_day
```

## Acknowledgments

* [Introduction to `dbplyr`](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html)

### Session Info

```{r child = here::here("R", "_session-info.Rmd")}
```
