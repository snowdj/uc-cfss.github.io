---
title: "Getting data from the web: API access"
author: "[MACS 30500](https://cfss.uchicago.edu) <br /> University of Chicago"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.retina = 2, fig.width = 12)

library(tidyverse)
library(broom)
library(jsonlite)
library(stringr)
library(XML)
library(curl)
library(repurrrsive)
library(listviewer)
library(wordcloud)
library(tidytext)
library(manifestoR)
library(httr)
library(rtweet)
library(viridis)

set.seed(1234)
theme_set(theme_minimal(base_size = rcfss::base_size))
```

# Methods for obtaining data online

* Click and download
* Install and play
* API query
* Scraping

---

# Click and download

* `read.csv` or `readr::read_csv`
* `downloader` package or `curl`

---

# Data supplied on the web

* Application programming interface (API)
* Client
* Server

---

# Install and play packages

* Packages with R functions written for existing APIs
* Useful because
    * reproducible
    * updating
    * ease
    * scaling

---

# `manifestoR`

* Collects and organizes political party manifestos from around the world
* Over 1000 parties from 1945 until today in over 50 countries on five continents
* [`manifestoR`](https://github.com/ManifestoProject/manifestoR)

---

# API authentication

* Key/token
* Obtain key
* Store in `.Rprofile`

```{r rprofile, eval = FALSE}
# in .Rprofile
options("this_is_my_key" = XXXX)

# later, in the R script:
key <- getOption("this_is_my_key")
```

---

# Load library and set API key

```{r manifestor-load, cache = FALSE}
library(manifestoR)

# retrieve API key stored in .Rprofile
mp_setapikey(key = getOption("manifesto_key"))
```

---

# Retrieve the database

```{r manifestor-db}
(mpds <- mp_maindataset())
```

---

```{r manifesto-dist, echo = FALSE}
mpds %>%
  filter(countryname == "Sweden") %>%
  count(partyname) %>%
  ggplot(aes(fct_reorder(partyname, n), n)) +
  geom_col() +
  labs(title = "Political manifestos published in Sweden",
       x = NULL,
       y = "Total (1948-present)") +
  coord_flip()
```

---

# Download manifestos

```{r manifestor-corpus, echo = FALSE, message = FALSE, warning = FALSE}
# download documents
docs <- mp_corpus(countryname == "United States" & edate > as.Date("2012-01-01"))

# generate wordcloud of most common terms
docs %>%
  tidy() %>%
  mutate(party = factor(party, levels = c(61320, 61620),
                        labels = c("Democratic Party", "Republican Party"))) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(party, word, sort = TRUE) %>%
  drop_na() %>%
  reshape2::acast(word ~ party, value.var = "n", fill = 0) %>%
  comparison.cloud(max.words = 200)
```

---

# Census data with `tidycensus`

* API to access data from US Census Bureau
    * Decennial census
    * American Community Survey
* Returns tidy data frames with (optional) `sf` geometry
* Search for variables with `load_variables()`

---

# Store API key

```{r tidycensus}
library(tidycensus)
```

```r
census_api_key("YOUR API KEY GOES HERE")
```

---

# Obtain data

```{r income-usa}
usa_inc <- get_acs(geography = "state", 
                   variables = c(medincome = "B19013_001"), 
                   year = 2016)
usa_inc
```

---

# Visualize data

```{r income-usa-plot, echo = FALSE, fig.asp = .7}
usa_inc %>%
  ggplot(aes(x = reorder(NAME, estimate), y = estimate)) +
  geom_pointrange(aes(ymin = estimate - moe,
                     ymax = estimate + moe),
                  size = .25) +
  coord_flip() +
  labs(title = "Household income by state",
       subtitle = "2012-2016 American Community Survey",
       x = "",
       y = "ACS estimate (bars represent margin of error)") +
  theme_minimal(base_size = rcfss::base_size * 0.7)
```


---

# Twitter API

* REST API
* Streaming API

* [`twitteR`](https://cran.rstudio.com/web/packages/twitteR/index.html)
* [`streamR`](https://cran.rstudio.com/web/packages/streamR/index.html)
* [`rtweet`](http://rtweet.info/)

---

# Using `rtweet`

```{r twitter}
library(rtweet)
```

* Requires a Twitter account
* Prompt to authorize application on first usage

---


# Searching tweets

```{r twitter-rstats}
rt <- search_tweets(
  q = "#rstats",
  n = 3000,
  include_rts = FALSE
)
rt
```

---

# Searching users

```{r twitter-count}
countvoncount <- get_timeline(user = "countvoncount", n = 1000)
countvoncount
```

---

# Visualizing tweets

```{r rstats-freq}
ts_plot(rt, by = "3 hours")
```

---

# Visualizing tweets


```{r rstats-freq-day}
ts_plot(rt, by = "1 hours")
```

---

# Visualizing tweets

```{r rstats-freq-clean, fig.height = 3.5}
ts_plot(rt, by = "3 hours") +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of #rstats Twitter statuses from past 9 days",
    subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
    caption = "\nSource: Data collected from Twitter's REST API via rtweet"
  )
```

---

# Exercise: Practice using `rtweet`

.pull-left[

![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Katy_Perry%E2%80%93Zenith_Paris.jpg/360px-Katy_Perry%E2%80%93Zenith_Paris.jpg)

]

.pull-right[

![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Kim_Kardashian_West_2014.jpg/320px-Kim_Kardashian_West_2014.jpg)

]

---

# Writing an API function

* No package for API
* Write your own function!
* [Open Movie Database](http://www.omdbapi.com/)

---

# Determine the shape of an API request

![](/img/ombd.png)

---

# Determine the shape of an API request

```http
http://www.omdbapi.com/?apikey=[apikey]&t=Sharknado&y=2013&plot=short&r=xml
```

```http
<?xml version="1.0" encoding="UTF-8"?><root response="True"><movie title="Sharknado" year="2013" rated="TV-14" released="11 Jul 2013" runtime="86 min" genre="Comedy, Horror, Sci-Fi" director="Anthony C. Ferrante" writer="Thunder Levin" actors="Ian Ziering, Tara Reid, John Heard, Cassandra Scerbo" plot="When a freak hurricane swamps Los Angeles, nature's deadliest killer rules sea, land, and air as thousands of sharks terrorize the waterlogged populace." language="English" country="USA" awards="1 win &amp; 2 nominations." poster="https://images-na.ssl-images-amazon.com/images/M/MV5BOTE2OTk4MTQzNV5BMl5BanBnXkFtZTcwODUxOTM3OQ@@._V1_SX300.jpg" metascore="N/A" imdbRating="3.3" imdbVotes="38,948" imdbID="tt2724064" type="movie"/></root>
```

---

# Create a request in R

```{r omdb-key}
# retrieve API key from .RProfile
omdb_key <- getOption("omdb_key")

# create url
request <- str_c("http://www.omdbapi.com/?apikey=", omdb_key, "&", "t=",
                 "Sharknado", "&", "y=", "2013", "&", "plot=", "short",
                 "&", "r=", "xml")
request
```

---

# Abstracting to a function

```{r omdb-function, dependson = "omdb-key"}
omdb <- function(Key, Title, Year, Plot, Format){
  baseurl <- "http://www.omdbapi.com/?"
  params <- c("apikey=", "t=", "y=", "plot=", "r=")
  values <- c(Key, Title, Year, Plot, Format)
  param_values <- map2_chr(params, values, str_c)
  args <- str_c(param_values, collapse = "&")
  str_c(baseurl, args)
}

omdb(omdb_key, "Sharknado", "2013", "short", "xml")
```

---

# Obtain data with `curl`

```{r omdb-json, dependson = "omdb-key", warning = FALSE}
request_sharknado <- omdb(omdb_key, "Sharknado", "2013", "short", "json")
con <- curl(request_sharknado)
answer_json <- readLines(con)
close(con)
answer_json %>% 
  prettify()
```

---

# JavaScript Object Notation (JSON)

```javascript
{
  "crust": "original",
  "toppings": ["cheese", "pepperoni", "garlic"],
  "status": "cooking",
  "customer": {
    "name": "Brian",
    "phone": "573-111-1111"
  }
}
```

---

# Parsing JSON

```{r parse-json, dependson = "omdb-json"}
answer_json %>% 
  fromJSON()
```

---

# Parsing JSON into a data frame

```{r json-df, dependson = "omdb-json"}
answer_json %>% 
  fromJSON() %>% 
  # remove ratings element for now
  list_modify(Ratings = NULL) %>%
  as_tibble()
```

---

# Introducing the easy way: `httr`

* GET
* POST
* PUT
* DELETE

---

# `GET()` Sharknado

```{r httr-json}
sharknado_json <- omdb(omdb_key, "Sharknado", "2013", "short", "json")
response_json <- GET(sharknado_json)
content(response_json, as = "parsed", type = "application/json")
```

---

# Headers

```{r httr-headers, dependson = "httr-json"}
headers(response_json)
```

---

# HTTP status code

```{r httr-status, dependson = "httr-json"}
status_code(response_json)
```

---

# HTTP status code

Code | Status
-------|--------|
1xx    | Informational
2xx    | Success
3xx    | Redirection
4xx    | Client error (you did something wrong)
5xx    | Server error (server did something wrong)

> [A more intuitive guide](https://www.flickr.com/photos/girliemac/sets/72157628409467125)

---

# Skip `omdb()`

```{r httr-get-only}
sharknado_2 <- GET("http://www.omdbapi.com/?",
                   query = list(t = "Sharknado 2: The Second One",
                                y = 2014,
                                plot = "short",
                                r = "json",
                                apikey = omdb_key))

content(sharknado_2)
```

---

# Messy API responses

```{r omdb-recursive, echo = FALSE, error = TRUE, warning = FALSE}
# omdb API function
omdb <- function(Key, Title, Year, Plot, Format){
  baseurl <- "http://www.omdbapi.com/?"
  params <- c("apikey=", "t=", "y=", "plot=", "r=")
  values <- c(Key, Title, Year, Plot, Format)
  param_values <- map2_chr(params, values, str_c)
  args <- str_c(param_values, collapse = "&")
  str_c(baseurl, args)
}

# use curl to execute the query
request_sharknado <- omdb(getOption("omdb_key"), "Sharknado",
                          "2013", "short", "json")
con <- curl(request_sharknado)
answer_json <- readLines(con)
close(con)

# convert to data frame
answer_json %>% 
  fromJSON() %>% 
  as_tibble()
```

---

# Whoops

```{r omdb-str}
sharknado <- answer_json %>% 
  fromJSON()

jsonedit(sharknado, mode = "view", elementId = "sharknado")
```

---

# Inspecting and exploring lists

```{r packages-lists, cache = FALSE, include = FALSE}
library(purrr)
library(repurrrsive)
```

```{r got-view}
jsonedit(got_chars, mode = "view", elementId = "got_chars")
```

---

# Name and position shortcuts

```{r got-name-name}
map(got_chars[1:4], "name")
```

* Equivalent to `function(x) x[["TEXT"]]`

---

# Name and position shortcuts

```{r got-name-int}
map(got_chars[5:8], 3)
```

* Equivalent to `function(x) x[[i]]`
    
---

# Name and position shortcuts with pipe

```{r got-name-pipe, eval = FALSE}
got_chars %>% 
  map("name")
got_chars %>% 
  map(3)
```
    
---

# Type-specific map

```{r got-name-chr}
map_chr(got_chars[9:12], "name")
map_chr(got_chars[13:16], 3)
```

---

# Extract multiple values

```{r got-subset-one}
# Victarion element
got_chars[[3]]

# specific elements for Victarion
got_chars[[3]][c("name", "culture", "gender", "born")]
```

---

# Adapt to `map()` framework

```r
map(.x, .f, ...)
```

* `.f` = `[`
* `...` = character vector identifying the names of the elements to extract

---

# Adapt to `map()` framework

```{r got-subset}
x <- map(got_chars, `[`, c("name", "culture", "gender", "born"))
str(x[16:17])
```

---

# `magrittr::extract()`

```{r got-subset-magrittr, message = FALSE}
library(magrittr)

x <- map(got_chars, extract, c("name", "culture", "gender", "born"))
str(x[18:19])
```

---

# Data frame output

```{r got-df}
map_df(got_chars, extract, c("name", "culture", "gender", "id", "born", "alive"))
```

---

# More robust approach

```{r got-df-robust}
got_chars %>% {
  tibble(
    name = map_chr(., "name"),
    culture = map_chr(., "culture"),
    gender = map_chr(., "gender"),       
    id = map_int(., "id"),
    born = map_chr(., "born"),
    alive = map_lgl(., "alive")
  )
}
```

---

# Exercise: simplify `gh_users`

![](https://avatars1.githubusercontent.com/u/583231?s=400&v=4)

---

# List inside a data frame

```{r gh-repos-view}
jsonedit(gh_repos, mode = "view", elementId = "gh_repos")
```

---

# Vector input to extraction shortcuts

```{r gh-repos-repo-name}
gh_repos %>%
  map_chr(c(1, 3))
```

---

# Get it into a data frame

> One row per repository, with variables identifying which GitHub user owns it, the repository name, etc.

---

# Create a data frame

## Usernames and `gh_repos`

```{r gh-repos-df}
(unames <- map_chr(gh_repos, c(1, 4, 1)))
(udf <- gh_repos %>%
    set_names(unames) %>% 
    enframe("username", "gh_repos"))
```

---

# Repos associated with each user

```{r gh-repos-length}
udf %>% 
  mutate(n_repos = map_int(gh_repos, length))
```

---

# Practice on a single user

```{r gh-repos-user1, collapse = TRUE}
# one_user is a list of repos for one user
one_user <- udf$gh_repos[[1]]

# one_user[[1]] is a list of info for one repo
one_repo <- one_user[[1]]
str(one_repo, max.level = 1, list.len = 5)
```

---

# Practice on a single user

```{r gh-repos-user1-2, collapse = TRUE}
# a highly selective list of tibble-worthy info for one repo
one_repo[c("name", "fork", "open_issues")]

# make a data frame of that info for all a user's repos
map_df(one_user, extract, c("name", "fork", "open_issues"))
```

---

# Scale up to all users

.center[

![](http://i0.kym-cdn.com/photos/images/facebook/000/531/557/a88.jpg)

]

---

# Scale up to all users

```{r gh-repos-inception}
udf %>% 
  mutate(repo_info = gh_repos %>%
           map(~ .x %>%
                 map_df(extract, c("name", "fork", "open_issues"))))
```

---

# Tidy the data frame

```{r gh-repos-df-unnest}
(rdf <- udf %>% 
   mutate(
     repo_info = gh_repos %>%
       map(~ .x %>%
             map_df(extract, c("name", "fork", "open_issues")))
   ) %>% 
   select(-gh_repos) %>% 
   tidyr::unnest())
```




