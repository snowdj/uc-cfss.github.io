---
title: "Statistical learning: regression"
author: "[MACS 30500](https://cfss.uchicago.edu) <br /> University of Chicago"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.retina = 2, fig.width = 12)

library(tidyverse)
library(modelr)
library(broom)
library(FNN)
library(here)

set.seed(1234)
theme_set(theme_minimal(base_size = rcfss::base_size))
```

<iframe width="800" height="450" src="https://www.youtube.com/embed/QwRISkyV_B8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---

```{r get_ad, include = FALSE, cache.extra = file.info(here("static", "data", "Advertising.csv"))}
# get advertising data
(advertising <- here("static", "data", "Advertising.csv") %>%
   read_csv() %>%
   tbl_df() %>%
   # remove id column
   select(-X1))
```

```{r plot_ad, dependson="get_ad", echo = FALSE}
# plot separate facets for relationship between ad spending and sales
plot_ad <- advertising %>%
  gather(method, spend, -Sales) %>%
  ggplot(aes(spend, Sales)) +
  facet_wrap(~ method, scales = "free_x") +
  geom_point() +
  labs(x = "Spending (in thousands of dollars)")
plot_ad
```

---

# Functional form

$$Y = f(X) + \epsilon$$

* Statistical learning refers to the set of approaches for estimating $f$

---

# Linear functional form

```{r plot_ad_fit, echo = FALSE, dependson = "plot_ad"}
plot_ad +
  geom_smooth(method = "lm", se = FALSE)
```

---

# Why estimate $f$?

* Prediction
* Inference
* How do we estimate $f$?
    * Parametric methods
    * Non-parametric methods

---

# Parametric methods

1. First make an assumption about the functional form of $f$
1. After a model has been selected, **fit** or **train** the model using the actual data

---

# OLS

```{r plot_parametric, dependson="get_ad", echo = FALSE}
method_model <- function(df) {
  lm(Sales ~ spend, data = df)
}

ad_pred <- advertising %>%
  gather(method, spend, -Sales) %>%
  group_by(method) %>%
  nest() %>%
  mutate(model = map(data, method_model),
         pred = map(model, broom::augment)) %>%
  unnest(pred)

plot_ad +
  geom_smooth(method = "lm", se = FALSE) +
  geom_linerange(data = ad_pred,
                 aes(ymin = Sales, ymax = .fitted),
                 color = "blue",
                 alpha = .5) 
```

---

# OLS

$$Y = \beta_0 + \beta_{1}X_1$$

* $Y =$ sales
* $X_{1} =$ advertising spending in a given medium
* $\beta_0 =$ intercept
* $\beta_1 =$ slope

---

# Non-parametric methods

* No assumptions about functional form
* Use data to estimate $f$ directly
    * Get close to data points
    * Avoid overcomplexity
* Requires large amount of observations

---

# $K$-Nearest Neighbors regression

```{r knn-1, echo = FALSE, dependson = "get_ad"}
advertising %>%
  gather(method, spend, -Sales) %>%
  group_by(method) %>%
  nest() %>%
  mutate(knn = map(data, ~ knn.reg(train = .x$spend,
                                   y = .x$Sales,
                                   test = data.frame(.x$spend),
                                   k = 1)),
         pred = map(knn, ~ .x$pred)) %>%
  unnest(data, pred) %>%
  ggplot(aes(spend, Sales)) +
  facet_wrap(~ method, scales = "free_x") +
  geom_point(alpha = .25) +
  geom_step(aes(y = pred), color = "blue") +
  labs(title = "K-Nearest Neighbor",
       subtitle = "K = 1",
       x = "Spending (in thousands of dollars)")
```

---

# $K$-Nearest Neighbors regression

```{r knn-9, echo = FALSE, dependson = "get_ad"}
advertising %>%
  gather(method, spend, -Sales) %>%
  group_by(method) %>%
  nest() %>%
  mutate(knn = map(data, ~ knn.reg(train = .x$spend,
                                   y = .x$Sales,
                                   test = data.frame(.x$spend),
                                   k = 9)),
         pred = map(knn, ~ .x$pred)) %>%
  unnest(data, pred) %>%
  ggplot(aes(spend, Sales)) +
  facet_wrap(~ method, scales = "free_x") +
  geom_point(alpha = .25) +
  geom_step(aes(y = pred), color = "blue") +
  labs(title = "K-Nearest Neighbor",
       subtitle = "K = 9",
       x = "Spending (in thousands of dollars)")
```

---

# Linear models

$$y = \beta_0 + \beta_1 \times x$$

```{r sim-plot, echo = FALSE}
ggplot(sim1, aes(x, y)) + 
  geom_point()
```

---

# Linear models

```{r sim-random-fit, echo = FALSE}
models <- tibble(
  a1 = runif(250, -20, 40),
  a2 = runif(250, -5, 5)
)

ggplot(sim1, aes(x, y)) + 
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = 1/4) +
  geom_point()
```

---

# Least squares regression

```{r sim-error, echo = FALSE}
dist1 <- sim1 %>% 
  mutate(
    dodge = rep(c(-1, 0, 1) / 20, 10),
    x1 = x + dodge,
    pred = 7 + x1 * 1.5
  )

ggplot(dist1, aes(x1, y)) + 
  geom_abline(intercept = 7, slope = 1.5, colour = "grey40") +
  geom_point(colour = "grey40") +
  geom_linerange(aes(ymin = y, ymax = pred), colour = "#3366FF")
```

---

# Estimating a linear model using `lm()`

```{r sim-lm}
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

---

# `str(lm())`

```{r lm-str}
str(sim1_mod)
```

---

# Predicted values

```{r add-predict-data, echo = FALSE}
grid <- sim1 %>% 
  data_grid(x) 
```

```{r add-predict, echo = FALSE}
grid <- augment(sim1_mod, newdata = grid)
```

```{r plot-lm-predict, echo = FALSE}
ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = .fitted), data = grid, color = "red", size = 1) +
  geom_point(aes(y = .fitted), data = grid, color = "blue", size = 3)
```

---

# Residuals

```{r resids, echo = FALSE}
sim1_resid <- augment(sim1_mod)

ggplot(sim1_resid, aes(.resid)) + 
  geom_freqpoly(binwidth = 0.5)
```

---

# Overall `gapminder` model

```{r load-gapminder, include = FALSE}
library(gapminder)
gapminder
```

```{r lifeExp-by-country, fig.height = 6}
ggplot(gapminder, aes(year, lifeExp, group = country)) +
    geom_line(alpha = 1/3)
```

---

# Overall `gapminder` model

```{r lifeExp-mod, echo = FALSE}
gapminder_mod <- lm(lifeExp ~ year, data = gapminder)

grid <- gapminder %>% 
  data_grid(year, country) 

grid <- augment(gapminder_mod, newdata = grid) 

ggplot(gapminder, aes(year, group = country)) +
  geom_line(aes(y = lifeExp), alpha = .2) +
  geom_line(aes(y = .fitted), data = grid, color = "red", size = 1)
```

---

# `broom::tidy()`

```{r tidy}
tidy(gapminder_mod)

tidy(gapminder_mod) %>%
  str()
```

---

# `broom::augment()`

```{r augment}
augment(gapminder_mod)
```

---

# `broom::glance()`

```{r glance}
glance(gapminder_mod)
```

---

# Separate model for USA

```{r gapminder-us, echo = FALSE}
gapminder %>%
  filter(country == "United States") %>%
  ggplot(aes(year, lifeExp)) +
  geom_line() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "United States")
```

---

# `map()` and nested data frames

```{r nest}
by_country <- gapminder %>% 
  group_by(country, continent) %>% 
  nest()

by_country
```

---

# `map()` and nested data frames

```{r nest-view}
by_country$data[[1]]
```

---

# `map()` and nested data frames

```{r model-function}
country_model <- function(df) {
  lm(lifeExp ~ year, data = df)
}
```

```{r map-model-column}
by_country <- by_country %>%
  mutate(model = map(data, country_model))
by_country
```

---

# `map()` and nested data frames

```{r map-model-filter}
by_country %>% 
  filter(continent == "Europe")
```

---

# Unnesting

```{r map2}
by_country <- by_country %>% 
  mutate(resids = map2(data, model, add_residuals))
by_country
```

---

# Unnesting

```{r unnest}
resids <- unnest(by_country, resids)
resids
```

---

# Unnesting

```{r unnest-2, dependson = "resids", fig.height = 5}
ggplot(resids, aes(year, resid)) +
    geom_line(aes(group = country), alpha = 1 / 3) + 
    geom_smooth(se = FALSE)
```

---

# Exercise: linear regression with `scorecard`

![](https://images.theconversation.com/files/211075/original/file-20180319-31614-13s320u.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=496&fit=clip)

---

# Titanic

[![Sinking of the *Titanic*](https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg)](http://www.ultimatetitanic.com/the-sinking/)

---

# Titanic

<iframe width="560" height="315" src="https://www.youtube.com/embed/WNIPqafd4As?start=175" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---

# Titanic

<div style="width:100%;height:0;padding-bottom:39%;position:relative;"><iframe src="https://giphy.com/embed/wl19jJV69LRNS" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>
    
---

# Get data

```{r titanic_data, message = FALSE}
library(titanic)
titanic <- titanic_train %>%
  as_tibble()

glimpse(titanic)
```

---

# Linear regression

```{r titanic_ols, echo = FALSE}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

---

# Linear regression

```{r titanic_ols_old, echo = FALSE}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  xlim(0, 200)
```

---

# Logistic regression

$$\Pr(\text{survival} = \text{Yes} | \text{age})$$

* Predicted probability of surviving

---

# Logistic regression

```{r titanic_age_gl}
survive_age <- glm(Survived ~ Age, data = titanic, family = binomial)
summary(survive_age)
```

---

# Logistic regression

```{r titanic_age_glm_plot, echo = FALSE}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE)
```

---

# Logistic regression

```{r titanic_age_glm_plot_wide, echo = FALSE}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE, fullrange = TRUE) +
  xlim(0,200)
```

---

# Multiple predictors

```{r survive_age_woman, echo = FALSE}
survive_age_woman <- glm(Survived ~ Age + Sex, data = titanic,
                         family = binomial)
summary(survive_age_woman)
```

---

# Multiple predictors

```{r survive_age_woman_pred, echo = FALSE}
titanic_age_sex <- augment(survive_age_woman,
                           newdata = data_grid(titanic, Age, Sex),
                           type.predict = "response")
```

```{r survive_age_woman_plot, dependson="survive_age_woman", echo = FALSE}
ggplot(titanic_age_sex, aes(Age, .fitted, color = Sex)) +
  geom_line() +
  labs(title = "Probability of Surviving the Titanic",
       y = "Predicted Probability of Survival",
       color = "Sex")
```

---

# Quadratic terms

```{r straight_line, echo = FALSE}
sim_line <- tibble(x = runif(1000),
                   y = x * 1)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

---

# Quadratic terms

```{r parabola, echo = FALSE}
sim_line <- tibble(x = runif(1000, -1, 1),
                   y = x^2 + x)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

---

# Quadratic terms

```{r quadratic, echo = FALSE}
sim_line <- tibble(x = runif(1000, -1, 1),
                   y = x^3 + x^2 + x)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

---

# Quadratic terms

```{r titanic-square, echo = FALSE}
survive_age_square <- glm(Survived ~ Age + I(Age^2), data = titanic,
                          family = binomial)

augment(survive_age_square,
        newdata = data_grid(titanic, Age),
        type.predict = "response") %>%
  ggplot(aes(Age, .fitted)) +
  geom_line() +
  labs(title = "Relationship Between Age and Surviving the Titanic",
       y = "Predicted Probability of Survival")
```

---

# Interactive terms

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender}$$

--

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender} + \beta_{3}(\text{age} \times \text{gender})$$

---

# Interactive terms

```{r age_woman_cross, echo = FALSE}
survive_age_woman_x <- glm(Survived ~ Age * Sex, data = titanic,
                           family = binomial)
```

```{r age_woman_cross_pred, dependson="age_woman_cross", echo = FALSE}
titanic_age_sex_x <- augment(survive_age_woman_x,
                             newdata = data_grid(titanic, Age, Sex),
                             type.predict = "response")
```

```{r age_woman_plot, dependson="age_woman_cross", echo = FALSE}
ggplot(titanic_age_sex_x, aes(Age, .fitted, color = Sex)) +
  geom_line() +
  labs(title = "Probability of Surviving the Titanic",
       y = "Predicted Probability of Survival",
       color = "Sex")
```

---

# Accuracy of predictions

```{r accuracy_age, dependson="titanic_age_glm"}
age_accuracy <- augment(survive_age, type.predict = "response") %>%
  mutate(.pred = as.numeric(.fitted > .5))

mean(age_accuracy$Survived != age_accuracy$.pred, na.rm = TRUE)
```

--

```{r accuracy_age_gender_x, dependson="age_woman_cross"}
x_accuracy <- augment(survive_age_woman_x, type.predict = "response") %>%
  mutate(.pred = as.numeric(.fitted > .5))

mean(x_accuracy$Survived != x_accuracy$.pred, na.rm = TRUE)
```

---

# Exercise: depression and voting

<div style="width:100%;height:0;padding-bottom:75%;position:relative;"><iframe src="https://giphy.com/embed/4bjIKBOWUnVPICCzJc" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div>
