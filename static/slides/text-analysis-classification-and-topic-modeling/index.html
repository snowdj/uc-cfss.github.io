<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Text analysis: classification and topic modeling</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACS 30500   University of Chicago" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Text analysis: classification and topic modeling
### <a href="https://cfss.uchicago.edu">MACS 30500</a> <br /> University of Chicago

---




# Supervised learning

1. Hand-code a small set of documents `\(N = 1000\)`
1. Train a statistical learning model on the hand-coded data
1. Evaluate the effectiveness of the statistical learning model
1. Apply the final model to the remaining set of documents `\(N = 1000000\)`

---

# `USCongress`


```
## Rows: 4,449
## Columns: 7
## $ ID       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…
## $ cong     &lt;dbl&gt; 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 1…
## $ billnum  &lt;dbl&gt; 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4…
## $ h_or_sen &lt;chr&gt; "HR", "HR", "HR", "HR", "HR", "HR", "HR", "HR", "HR", "HR", "…
## $ major    &lt;dbl&gt; 18, 18, 18, 18, 5, 21, 15, 18, 18, 18, 18, 16, 18, 12, 2, 3, …
## $ text     &lt;chr&gt; "To suspend temporarily the duty on Fast Magenta 2 Stage.", "…
## $ label    &lt;fct&gt; "Foreign trade", "Foreign trade", "Foreign trade", "Foreign t…
```


```
## [1] "To suspend temporarily the duty on Fast Magenta 2 Stage."                                                                                                                                                                                
## [2] "To suspend temporarily the duty on Fast Black 286 Stage."                                                                                                                                                                                
## [3] "To suspend temporarily the duty on mixtures of Fluazinam."                                                                                                                                                                               
## [4] "To reduce temporarily the duty on Prodiamine Technical."                                                                                                                                                                                 
## [5] "To amend the Immigration and Nationality Act in regard to Caribbean-born immigrants."                                                                                                                                                    
## [6] "To amend title 38, United States Code, to extend the eligibility for housing loans guaranteed by the Secretary of Veterans Affairs under the Native American Housing Loan Pilot Program to veterans who are married to Native Americans."
```

---

# Split the data set


```r
set.seed(123)

congress &lt;- congress %&gt;%
  mutate(major = factor(x = major, levels = major, labels = label))

congress_split &lt;- initial_split(data = congress, strata = major, prop = .8)
congress_split
## &lt;Analysis/Assess/Total&gt;
## &lt;3560/889/4449&gt;

congress_train &lt;- training(congress_split)
congress_test &lt;- testing(congress_split)
```

---

# Preprocessing the data frame


```r
congress_rec &lt;- recipe(major ~ text, data = congress_train)
```


```r
library(textrecipes)

congress_rec &lt;- congress_rec %&gt;%
  step_tokenize(text) %&gt;%
  step_stopwords(text) %&gt;%
  step_tokenfilter(text, max_tokens = 500) %&gt;%
  step_tfidf(text)
```

---

# Train a model


```r
library(discrim)
nb_spec &lt;- naive_Bayes() %&gt;%
  set_mode("classification") %&gt;%
  set_engine("naivebayes")

nb_spec
## Naive Bayes Model Specification (classification)
## 
## Computational engine: naivebayes
```

---

# Train a model


```r
nb_wf &lt;- workflow() %&gt;%
  add_recipe(congress_rec) %&gt;%
  add_model(nb_spec)

nb_wf %&gt;%
  fit(data = congress_train)
## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: naive_Bayes()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## ● step_tokenize()
## ● step_stopwords()
## ● step_tokenfilter()
## ● step_tfidf()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## ================================== Naive Bayes ================================== 
##  
##  Call: 
## naive_bayes.default(x = maybe_data_frame(x), y = y, usekernel = TRUE)
## 
## --------------------------------------------------------------------------------- 
##  
## Laplace smoothing: 0
## 
## --------------------------------------------------------------------------------- 
##  
##  A priori probabilities: 
## 
##                                  Foreign trade 
##                                    0.088202247 
##                           Labor and employment 
##                                    0.058988764 
##              Public lands and water management 
##                                    0.110674157 
##        Banking, finance, and domestic commerce 
##                                    0.061516854 
##                                        Defense 
##                                    0.049719101 
##                      Law, crime, family issues 
##                                    0.064606742 
## Civil rights, minority issues, civil liberties 
##                                    0.017696629 
##                                         Health 
##                                    0.137359551 
##          International affairs and foreign aid 
##                                    0.028370787 
##                          Government operations 
##                                    0.085393258 
##                           Other, miscellaneous 
##                                    0.006460674 
##                                 Transportation 
##                                    0.039044944 
##                                      Education 
##                                    0.048595506 
##          Space, technology, and communications 
##                                    0.019101124 
##                                    Environment 
##                                    0.046348315 
##                                 Macroeconomics 
##                                    0.035393258 
##                                 Social welfare 
##                                    0.020786517 
##                                         Energy 
##                                    0.030617978 
## 
## ...
## and 1715 more lines.
```

---

# Evaluation


```r
set.seed(123)

congress_folds &lt;- vfold_cv(data = congress_train, strata = major)
```


```r
nb_cv &lt;- nb_wf %&gt;%
  fit_resamples(
    congress_folds,
    control = control_resamples(save_pred = TRUE)
  )
```


```r
nb_cv_metrics &lt;- collect_metrics(nb_cv)
nb_cv_predictions &lt;- collect_predictions(nb_cv)

nb_cv_metrics
## # A tibble: 2 x 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy multiclass 0.137    10 0.00532 Preprocessor1_Model1
## 2 roc_auc  hand_till  0.536    10 0.00488 Preprocessor1_Model1
```

---

# Receiver operator curve

&lt;img src="index_files/figure-html/nb-roc-curve-1.png" width="864" /&gt;

---

# Confusion matrix

&lt;img src="index_files/figure-html/nb-confusion-1.png" width="864" /&gt;

---

# Compare to the null model


```r
null_classification &lt;- null_model() %&gt;%
  set_engine("parsnip") %&gt;%
  set_mode("classification")

null_cv &lt;- workflow() %&gt;%
  add_recipe(congress_rec) %&gt;%
  add_model(null_classification) %&gt;%
  fit_resamples(
    congress_folds
  )

null_cv %&gt;%
  collect_metrics()
## # A tibble: 2 x 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy multiclass 0.137    10 0.00532 Preprocessor1_Model1
## 2 roc_auc  hand_till  0.5      10 0       Preprocessor1_Model1
```

---

# Class imbalance

&lt;img src="index_files/figure-html/major-topic-dist-1.png" width="864" /&gt;

---

# Downsampling


```r
library(themis)

# build on existing recipe
congress_rec &lt;- congress_rec %&gt;%
  step_downsample(major)
congress_rec
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          1
## 
## Operations:
## 
## Tokenization for text
## Stop word removal for text
## Text filtering for text
## Term frequency-inverse document frequency with text
## Down-sampling based on major
```

---

# Support vector machine


```r
svm_spec &lt;- svm_rbf() %&gt;%
  set_mode("classification") %&gt;%
  set_engine("liquidSVM")

svm_spec
## Radial Basis Function Support Vector Machine Specification (classification)
## 
## Computational engine: liquidSVM
```

---

# Downsampling


```r
svm_wf &lt;- workflow() %&gt;%
  add_recipe(congress_rec) %&gt;%
  add_model(svm_spec)
```


```r
set.seed(123)

svm_cv &lt;- fit_resamples(
  svm_wf,
  congress_folds,
  metrics = metric_set(accuracy),
  control = control_resamples(save_pred = TRUE)
)
```


```r
svm_cv_metrics &lt;- collect_metrics(svm_cv)
svm_cv_predictions &lt;- collect_predictions(svm_cv)

svm_cv_metrics
## # A tibble: 1 x 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy multiclass 0.347    10  0.0125 Preprocessor1_Model1
```

---

# Confusion matrix

&lt;img src="index_files/figure-html/svm-confusion-1.png" width="864" /&gt;


---

# Topic modeling

* Themes
* Probabilistic topic models
* Latent Dirichlet allocation

---

# Food and animals

1. I ate a banana and spinach smoothie for breakfast.
1. I like to eat broccoli and bananas.
1. Chinchillas and kittens are cute.
1. My sister adopted a kitten yesterday.
1. Look at this cute hamster munching on a piece of broccoli.

---

# LDA document structure

* Decide on the number of words N the document will have
    * [Dirichlet probability distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)
    * Fixed set of `\(k\)` topics
* Generate each word in the document:
    * Pick a topic
    * Generate the word
* LDA backtracks from this assumption

---

# `r/jokes`

&lt;blockquote class="reddit-card" data-card-created="1552319072"&gt;&lt;a href="https://www.reddit.com/r/Jokes/comments/a593r0/twenty_years_from_now_kids_are_gonna_think_baby/"&gt;Twenty years from now, kids are gonna think "Baby it's cold outside" is really weird, and we're gonna have to explain that it has to be understood as a product of its time.&lt;/a&gt; from &lt;a href="http://www.reddit.com/r/Jokes"&gt;r/Jokes&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//embed.redditmedia.com/widgets/platform.js" charset="UTF-8"&gt;&lt;/script&gt;

---

# `r/jokes` dataset


```
## Rows: 194,553
## Columns: 4
## $ body  &lt;chr&gt; "Now I have to say \"Leroy can you please paint the fence?\"", "…
## $ id    &lt;chr&gt; "5tz52q", "5tz4dd", "5tz319", "5tz2wj", "5tz1pc", "5tz1o1", "5tz…
## $ score &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 15, 0, 0, 3, 1, 0, 3, 2, 2, 3, 0, …
## $ title &lt;chr&gt; "I hate how you cant even say black paint anymore", "What's the …
```

---

# Create the recipe


```r
set.seed(123) # set seed for random sampling

jokes_rec &lt;- recipe(~., data = jokes) %&gt;%
  step_sample(size = 1e04) %&gt;%
  step_tokenize(title, body) %&gt;%
  step_tokenmerge(title, body, prefix = "joke") %&gt;%
  step_stopwords(joke) %&gt;%
  step_ngram(joke, num_tokens = 5, min_num_tokens = 1) %&gt;%
  step_tokenfilter(joke, max_tokens = 2500) %&gt;%
  step_tf(joke)
```

---

# Bake the recipe


```r
jokes_prep &lt;- prep(jokes_rec)

jokes_df &lt;- bake(jokes_prep, new_data = NULL)
jokes_df %&gt;%
  slice(1:5)
## # A tibble: 5 x 2,502
##   id     score tf_joke_0 tf_joke_1 tf_joke_1_2 tf_joke_10 tf_joke_100
##   &lt;fct&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1 36bbmw     1         0         0           0          0           0
## 2 4mvekf     5         0         0           0          0           0
## 3 2tj7sk     0         0         0           0          0           0
## 4 2qhtww     0         0         0           0          0           0
## 5 21n2rz    11         0         0           0          0           0
## # … with 2,495 more variables: tf_joke_1000 &lt;dbl&gt;, tf_joke_11 &lt;dbl&gt;,
## #   tf_joke_12 &lt;dbl&gt;, tf_joke_14 &lt;dbl&gt;, tf_joke_15 &lt;dbl&gt;, tf_joke_16 &lt;dbl&gt;,
## #   tf_joke_18 &lt;dbl&gt;, tf_joke_2 &lt;dbl&gt;, tf_joke_20 &lt;dbl&gt;,
## #   tf_joke_20_years &lt;dbl&gt;, tf_joke_200 &lt;dbl&gt;, tf_joke_24 &lt;dbl&gt;,
## #   tf_joke_25 &lt;dbl&gt;, tf_joke_2nd &lt;dbl&gt;, tf_joke_3 &lt;dbl&gt;, tf_joke_30 &lt;dbl&gt;,
## #   tf_joke_3rd &lt;dbl&gt;, tf_joke_4 &lt;dbl&gt;, tf_joke_40 &lt;dbl&gt;, tf_joke_45 &lt;dbl&gt;,
## #   tf_joke_5 &lt;dbl&gt;, tf_joke_50 &lt;dbl&gt;, tf_joke_500 &lt;dbl&gt;, tf_joke_6 &lt;dbl&gt;,
## #   tf_joke_60 &lt;dbl&gt;, tf_joke_69 &lt;dbl&gt;, tf_joke_7 &lt;dbl&gt;, tf_joke_8 &lt;dbl&gt;,
## #   tf_joke_80 &lt;dbl&gt;, tf_joke_9 &lt;dbl&gt;, tf_joke_9_11 &lt;dbl&gt;, tf_joke_90 &lt;dbl&gt;,
## #   tf_joke_able &lt;dbl&gt;, tf_joke_absolutely &lt;dbl&gt;, tf_joke_accept &lt;dbl&gt;,
## #   tf_joke_accident &lt;dbl&gt;, tf_joke_accidentally &lt;dbl&gt;,
## #   tf_joke_according &lt;dbl&gt;, tf_joke_account &lt;dbl&gt;, tf_joke_across &lt;dbl&gt;,
## #   tf_joke_across_street &lt;dbl&gt;, tf_joke_act &lt;dbl&gt;, tf_joke_action &lt;dbl&gt;,
## #   tf_joke_actually &lt;dbl&gt;, tf_joke_adam &lt;dbl&gt;, tf_joke_add &lt;dbl&gt;,
## #   tf_joke_added &lt;dbl&gt;, tf_joke_admit &lt;dbl&gt;, tf_joke_advice &lt;dbl&gt;,
## #   tf_joke_afraid &lt;dbl&gt;, tf_joke_africa &lt;dbl&gt;, tf_joke_african &lt;dbl&gt;,
## #   tf_joke_afternoon &lt;dbl&gt;, tf_joke_age &lt;dbl&gt;, tf_joke_aged &lt;dbl&gt;,
## #   tf_joke_agent &lt;dbl&gt;, tf_joke_ago &lt;dbl&gt;, tf_joke_agree &lt;dbl&gt;,
## #   tf_joke_agreed &lt;dbl&gt;, tf_joke_agrees &lt;dbl&gt;, tf_joke_ah &lt;dbl&gt;,
## #   tf_joke_ahead &lt;dbl&gt;, tf_joke_aids &lt;dbl&gt;, tf_joke_ain't &lt;dbl&gt;,
## #   tf_joke_air &lt;dbl&gt;, tf_joke_airplane &lt;dbl&gt;, tf_joke_airport &lt;dbl&gt;,
## #   tf_joke_alcohol &lt;dbl&gt;, tf_joke_alien &lt;dbl&gt;, tf_joke_alive &lt;dbl&gt;,
## #   tf_joke_alley &lt;dbl&gt;, tf_joke_allowed &lt;dbl&gt;, tf_joke_almost &lt;dbl&gt;,
## #   tf_joke_alone &lt;dbl&gt;, tf_joke_along &lt;dbl&gt;, tf_joke_alphabet &lt;dbl&gt;,
## #   tf_joke_already &lt;dbl&gt;, tf_joke_alright &lt;dbl&gt;, tf_joke_also &lt;dbl&gt;,
## #   tf_joke_alternative &lt;dbl&gt;, tf_joke_always &lt;dbl&gt;, tf_joke_amazed &lt;dbl&gt;,
## #   tf_joke_amazing &lt;dbl&gt;, tf_joke_america &lt;dbl&gt;, tf_joke_american &lt;dbl&gt;,
## #   tf_joke_americans &lt;dbl&gt;, tf_joke_amount &lt;dbl&gt;, tf_joke_anal &lt;dbl&gt;,
## #   tf_joke_andy &lt;dbl&gt;, tf_joke_angel &lt;dbl&gt;, tf_joke_angrily &lt;dbl&gt;,
## #   tf_joke_angry &lt;dbl&gt;, tf_joke_animal &lt;dbl&gt;, tf_joke_animals &lt;dbl&gt;,
## #   tf_joke_anniversary &lt;dbl&gt;, tf_joke_announced &lt;dbl&gt;, tf_joke_annoyed &lt;dbl&gt;,
## #   tf_joke_another &lt;dbl&gt;, tf_joke_another_man &lt;dbl&gt;,
## #   tf_joke_another_one &lt;dbl&gt;, …
```

---

# Convert to document-term matrix


```r
jokes_dtm &lt;- jokes_df %&gt;%
  pivot_longer(cols = -c(id, score),
               names_to = "token",
               values_to = "n") %&gt;%
  filter(n != 0) %&gt;%
  # clean the token column so it just includes the token
  # drop empty levels from id - this includes jokes which did not
  # have any tokens retained after step_tokenfilter()
  mutate(token = str_remove(string = token, pattern = "tf_joke_"),
         id = fct_drop(f = id)) %&gt;%
  cast_dtm(document = id, term = token, value = n)
jokes_dtm
## &lt;&lt;DocumentTermMatrix (documents: 9956, terms: 2500)&gt;&gt;
## Non-/sparse entries: 138201/24751799
## Sparsity           : 99%
## Maximal term length: 34
## Weighting          : term frequency (tf)
```

---

# `\(k=4\)`


```r
jokes_lda4 &lt;- LDA(jokes_dtm, k = 4, control = list(seed = 123))
```

&lt;img src="index_files/figure-html/jokes-4-topn-1.png" width="864" /&gt;

---

# `\(k=12\)`



&lt;img src="index_files/figure-html/jokes-12-topn-1.png" width="864" /&gt;

---

# Perplexity

* A statistical measure of how well a probability model predicts a sample
* Given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents
* Perplexity for LDA model with 12 topics
    * 1003.3647235

---

# Perplexity



&lt;img src="index_files/figure-html/jokes_lda_compare_viz-1.png" width="864" /&gt;

---

# `\(k=100\)`

&lt;img src="index_files/figure-html/jokes-100-topn-1.png" width="864" /&gt;

---

# LDAvis

* Interactive visualization of LDA model results
1. What is the meaning of each topic?
1. How prevalent is each topic?
1. How do the topics relate to each other?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://cfss.uchicago.edu/slides/macros.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
