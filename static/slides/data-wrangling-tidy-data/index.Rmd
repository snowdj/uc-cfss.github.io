---
title: "Data wrangling: tidy data"
author: "[MACS 30500](https://cfss.uchicago.edu) <br /> University of Chicago"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  cache = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.retina = 2, fig.width = 12
)

library(tidyverse)
library(nycflights13)
library(rcfss)
library(knitr)
library(here)

library(tidyverse)
theme_set(theme_minimal(base_size = rcfss::base_size))
```

# `readr` vs. base R

```{r compare-speed-small, dependson = "data-gen", message = FALSE, echo = FALSE}
library(microbenchmark)

results_small <- microbenchmark(
  read.csv = read.csv(here("static", "data", "sim-data-small.csv")),
  read_csv = read_csv(here("static", "data", "sim-data-small.csv"))
)
```

```{r compare-speed-small-plot, dependson = "compare-speed-small", message = FALSE, echo = FALSE}
autoplot(results_small) +
  scale_y_log10() +
  labs(
    title = str_c("Number of observations:",
      nrow(read_csv(here("static", "data", "sim-data-small.csv"))),
      sep = " "
    ),
    y = "Time [milliseconds], logged"
  )
```

---

# `readr` vs. base R

```{r compare-speed-large, dependson = "data-gen", message = FALSE, echo = FALSE}
results_large <- microbenchmark(
  read.csv = read.csv(here("static", "data", "sim-data-large.csv")),
  read_csv = read_csv(here("static", "data", "sim-data-large.csv"))
)
```

```{r compare-speed-large-plot, dependson = "compare-speed-large", message = FALSE, echo = FALSE}
autoplot(results_large) +
  scale_y_log10() +
  labs(
    title = str_c("Number of observations:",
      nrow(read_csv(here("static", "data", "sim-data-large.csv"))),
      sep = " "
    ),
    y = "Time [milliseconds], logged"
  )
```

---

# Alternative file formats

* CSV
* RDS
* Feather
* Excel
* SPSS/Stata

---

# `challenge`

```{r challenge, echo = FALSE}
challenge <- read_csv(
  readr_example("challenge.csv"),
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)

challenge
```

---

# RDS

```{r rds, dependson = "challenge", include = FALSE}
# write to csv
write_csv(challenge, here("static", "data", "challenge.csv"))

# write to/read from rds
write_rds(challenge, here("static", "data", "challenge.rds"), compress = "gz")
read_rds(here("static", "data", "challenge.rds"))
```

```{r rds-2, dependson = c("challenge", "rds"), message = FALSE}
# compare file size
file.info(here("static", "data", "challenge.rds"))$size %>%
  utils:::format.object_size("auto")

file.info(here("static", "data", "challenge.csv"))$size %>%
  utils:::format.object_size("auto")
```

---

# RDS

```{r rds-3, dependson = c("challenge", "rds"), echo = FALSE}
# compare read speeds
microbenchmark(
  read_csv = read_csv(
    readr_example("challenge.csv"),
    col_types = cols(
      x = col_double(),
      y = col_date()
    )
  ),
  read_rds = read_rds(here("static", "data", "challenge.rds"))
) %>%
  autoplot() +
  labs(y = "Time [microseconds], logged")
```

---

# `feather`

```{r feather, dependson = "challenge", include = FALSE}
library(arrow)

write_feather(x = challenge, sink = here("static", "data", "challenge.feather"))
read_feather(file = here("static", "data", "challenge.feather"))
```

```{r feather-2, dependson = "challenge", message = FALSE, echo = FALSE}
microbenchmark(
  read_csv = read_csv(
    readr_example("challenge.csv"),
    col_types = cols(
      x = col_double(),
      y = col_date()
    )
  ),
  read_rds = read_rds(here("static", "data", "challenge.rds")),
  read_feather = read_feather(file = here("static", "data", "challenge.feather"))
) %>%
  autoplot() +
  scale_y_log10(labels = scales::comma) +
  labs(y = "Time [microseconds], logged")
```

---

# `readxl`

```{r readxl}
library(readxl)

xlsx_example <- readxl_example(path = "datasets.xlsx")
read_excel(path = xlsx_example)
```

---

# `readxl`

```{r readxl-sheets, dependson = "readxl"}
excel_sheets(path = xlsx_example)
```

```{r readxl-select-sheet, dependson = "readxl"}
read_excel(path = xlsx_example, sheet = "chickwts")
```

---

# `haven`

## SAS

```{r haven-sas}
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
  package = "haven"
))
```

---

# `haven`

## SPSS

```{r haven-spss}
read_sav(file = system.file("examples", "iris.sav",
  package = "haven"
))
```

---

# `haven`

## Stata

```{r haven-stata}
read_dta(file = system.file("examples", "iris.dta",
  package = "haven"
))
```

---

class: center

# Tidy data

![](https://r4ds.had.co.nz/images/tidy-1.png)

---

# Common tidying tasks

* Pivoting
    * Longer
    * Wider
* Separating
* Uniting

---

# Pivot longer

.pull-left[

```{r spread-columns}
table4a
```

]

--

.pull-right[

```{r pivot-longer}
pivot_longer(
  data = table4a,
  cols = c(`1999`, `2000`),
  names_to = "year",
  values_to = "cases"
)
```

]

---

# Pivot wider

.pull-left[

```{r spread-rows}
table2
```

]

--

.pull-right[

```{r pivot-wider}
pivot_wider(
  data = table2,
  names_from = type,
  values_from = count
)
```

]

---

# Separating

.pull-left[

```{r merged-columns}
table3
```

]

--

.pull-right[

```{r separate}
separate(
  data = table3,
  col = rate,
  into = c(
    "cases",
    "population"
  ),
  convert = TRUE
)
```

]

---

# Uniting

.pull-left[

```{r merged-rows}
table5
```

]

--

.pull-right[

```{r unite}
unite(
  data = table5,
  col = "new",
  century, year
)
```

]

---

# Uniting

.pull-left[

```{r merged-rows}
```

]

.pull-right[

```{r unite-underscore}
# remove underscore
unite(
  data = table5,
  col = "new",
  century, year,
  sep = ""
)
```

]
